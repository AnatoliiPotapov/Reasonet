09/27/2017 09:32:00 [program starts.]
09/27/2017 09:32:00 {'reduce_lr': 0.0, 'dropout_rnn': 0.3, 'pos': True, 'question_merge': 'self_attn', 'eval_per_epoch': 1, 'epochs': 20, 'question_layers': 3, 'pos_dim': 12, 'doc_layers': 3, 'seed': 411, 'save_last_only': False, 'model_dir': 'models', 'ner_size': 19, 'concat_rnn_layers': True, 'resume': '', 'rnn_padding': False, 'dropout_rnn_output': True, 'max_len': 15, 'data_file': 'SQuAD/data.msgpack', 'ner': True, 'weight_decay': 0, 'rnn_type': 'lstm', 'momentum': 0, 'log_per_updates': 3, 'grad_clipping': 10, 'learning_rate': 0.1, 'cuda': False, 'hidden_size': 128, 'ner_dim': 8, 'batch_size': 32, 'dropout_emb': 0.3, 'fix_embeddings': False, 'num_features': 4, 'pos_size': 56, 'tune_partial': 1000, 'optimizer': 'adamax', 'resume_options': False, 'use_qemb': True, 'log_file': 'output.log'}
09/27/2017 09:56:01 [program starts.]
09/27/2017 09:56:01 {'tune_partial': 1000, 'resume': '', 'doc_layers': 3, 'log_file': 'output.log', 'log_per_updates': 3, 'eval_per_epoch': 1, 'num_features': 4, 'pos': True, 'data_file': 'SQuAD/data.msgpack', 'learning_rate': 0.1, 'rnn_type': 'lstm', 'model_dir': 'models', 'pos_dim': 12, 'ner_dim': 8, 'save_last_only': False, 'cuda': False, 'concat_rnn_layers': True, 'dropout_rnn': 0.3, 'ner': True, 'question_merge': 'self_attn', 'grad_clipping': 10, 'epochs': 20, 'dropout_rnn_output': True, 'fix_embeddings': False, 'optimizer': 'adamax', 'max_len': 15, 'dropout_emb': 0.3, 'ner_size': 19, 'question_layers': 3, 'pos_size': 56, 'rnn_padding': False, 'reduce_lr': 0.0, 'seed': 411, 'resume_options': False, 'weight_decay': 0, 'hidden_size': 128, 'momentum': 0, 'batch_size': 32, 'use_qemb': True}
09/27/2017 09:56:27 [Data loaded.]
09/27/2017 09:56:29 Epoch 1
09/27/2017 09:57:01 updates[     1] train loss[9.96538] remaining[23:42:43]
09/27/2017 09:57:49 updates[     4] train loss[9.31764] remaining[15:01:48]
09/27/2017 09:59:02 updates[     7] train loss[9.09595] remaining[16:21:11]
09/27/2017 10:00:04 updates[    10] train loss[8.99515] remaining[16:03:49]
09/27/2017 10:00:52 updates[    13] train loss[8.94023] remaining[15:05:32]
09/27/2017 10:01:54 updates[    16] train loss[8.86766] remaining[15:06:47]
09/27/2017 10:02:43 updates[    19] train loss[8.82763] remaining[14:39:44]
09/27/2017 10:03:26 updates[    22] train loss[8.74514] remaining[14:04:21]
09/27/2017 10:04:52 updates[    25] train loss[8.68598] remaining[14:55:33]
09/27/2017 10:05:45 updates[    28] train loss[8.64067] remaining[14:42:58]
09/27/2017 10:06:58 updates[    31] train loss[8.59011] remaining[15:01:22]
09/27/2017 10:07:49 updates[    34] train loss[8.53125] remaining[14:47:35]
09/27/2017 10:08:34 updates[    37] train loss[8.46768] remaining[14:28:44]
09/27/2017 10:09:14 updates[    40] train loss[8.44093] remaining[14:07:29]
09/27/2017 10:09:52 updates[    43] train loss[8.37998] remaining[13:46:27]
09/27/2017 10:10:34 updates[    46] train loss[8.34190] remaining[13:31:44]
09/27/2017 10:11:17 updates[    49] train loss[8.28205] remaining[13:20:12]
09/27/2017 10:12:01 updates[    52] train loss[8.22280] remaining[13:10:15]
09/27/2017 10:12:38 updates[    55] train loss[8.18218] remaining[12:55:24]
09/27/2017 10:13:17 updates[    58] train loss[8.14917] remaining[12:44:08]
09/27/2017 10:14:04 updates[    61] train loss[8.10092] remaining[12:39:46]
09/27/2017 10:14:40 updates[    64] train loss[8.05965] remaining[12:28:17]
09/27/2017 10:15:08 updates[    67] train loss[8.02943] remaining[12:12:14]
09/27/2017 10:16:21 updates[    70] train loss[8.00126] remaining[12:25:30]
09/27/2017 10:16:56 updates[    73] train loss[7.97268] remaining[12:14:52]
09/27/2017 10:17:30 updates[    76] train loss[7.93888] remaining[12:04:48]
09/27/2017 10:18:04 updates[    79] train loss[7.90549] remaining[11:55:29]
09/27/2017 10:18:39 updates[    82] train loss[7.87973] remaining[11:47:09]
09/27/2017 10:19:36 updates[    85] train loss[7.84797] remaining[11:50:10]
09/27/2017 10:20:21 updates[    88] train loss[7.81352] remaining[11:47:47]
09/27/2017 10:20:55 updates[    91] train loss[7.78145] remaining[11:39:34]
09/27/2017 10:22:13 updates[    94] train loss[7.73837] remaining[11:52:45]
09/27/2017 10:22:57 updates[    97] train loss[7.70518] remaining[11:49:38]
09/27/2017 10:23:27 updates[   100] train loss[7.67335] remaining[11:40:31]
09/27/2017 10:23:55 updates[   103] train loss[7.63675] remaining[11:30:42]
09/27/2017 10:24:22 updates[   106] train loss[7.60501] remaining[11:21:29]
09/27/2017 10:25:55 updates[   109] train loss[7.59059] remaining[11:38:43]
09/27/2017 10:26:53 updates[   112] train loss[7.55371] remaining[11:41:27]
09/27/2017 10:27:47 updates[   115] train loss[7.53643] remaining[11:42:41]
09/27/2017 10:28:24 updates[   118] train loss[7.49447] remaining[11:37:34]
09/27/2017 10:29:14 updates[   121] train loss[7.47029] remaining[11:37:17]
09/27/2017 10:30:25 updates[   124] train loss[7.45356] remaining[11:44:11]
09/27/2017 10:31:04 updates[   127] train loss[7.42976] remaining[11:39:43]
09/27/2017 10:31:38 updates[   130] train loss[7.39974] remaining[11:34:10]
09/27/2017 10:32:11 updates[   133] train loss[7.37892] remaining[11:28:08]
09/27/2017 10:32:46 updates[   136] train loss[7.35350] remaining[11:23:20]
09/27/2017 10:33:23 updates[   139] train loss[7.33417] remaining[11:19:00]
09/27/2017 10:33:55 updates[   142] train loss[7.30865] remaining[11:13:32]
09/27/2017 10:34:32 updates[   145] train loss[7.28489] remaining[11:09:36]
09/27/2017 10:35:18 updates[   148] train loss[7.25677] remaining[11:08:36]
09/27/2017 10:35:58 updates[   151] train loss[7.24523] remaining[11:05:44]
09/27/2017 10:38:17 updates[   154] train loss[7.22579] remaining[11:30:19]
09/27/2017 10:39:09 updates[   157] train loss[7.21787] remaining[11:30:22]
09/27/2017 10:39:43 updates[   160] train loss[7.20055] remaining[11:25:25]
09/27/2017 10:40:22 updates[   163] train loss[7.19047] remaining[11:22:11]
09/27/2017 10:41:03 updates[   166] train loss[7.17149] remaining[11:19:26]
09/27/2017 10:41:52 updates[   169] train loss[7.14986] remaining[11:18:47]
09/27/2017 10:42:41 updates[   172] train loss[7.12323] remaining[11:18:09]
09/27/2017 10:43:13 updates[   175] train loss[7.10280] remaining[11:13:35]
09/27/2017 10:44:05 updates[   178] train loss[7.08385] remaining[11:13:38]
09/27/2017 10:45:15 updates[   181] train loss[7.06063] remaining[11:17:48]
09/27/2017 10:45:48 updates[   184] train loss[7.04402] remaining[11:13:30]
09/27/2017 10:46:26 updates[   187] train loss[7.04021] remaining[11:10:26]
09/27/2017 10:47:28 updates[   190] train loss[7.02167] remaining[11:12:45]
09/27/2017 10:48:33 updates[   193] train loss[7.01072] remaining[11:15:35]
09/27/2017 10:49:25 updates[   196] train loss[6.99903] remaining[11:15:21]
09/27/2017 10:50:31 updates[   199] train loss[6.98309] remaining[11:18:11]
09/27/2017 10:51:05 updates[   202] train loss[6.97243] remaining[11:14:26]
09/27/2017 10:51:41 updates[   205] train loss[6.95789] remaining[11:10:59]
09/27/2017 10:52:09 updates[   208] train loss[6.95171] remaining[11:06:11]
09/27/2017 10:52:55 updates[   211] train loss[6.93875] remaining[11:04:58]
09/27/2017 10:53:28 updates[   214] train loss[6.91862] remaining[11:01:09]
09/27/2017 10:54:13 updates[   217] train loss[6.90002] remaining[10:59:49]
09/27/2017 10:54:51 updates[   220] train loss[6.88632] remaining[10:57:08]
09/27/2017 10:55:27 updates[   223] train loss[6.87547] remaining[10:54:13]
09/27/2017 10:56:22 updates[   226] train loss[6.85624] remaining[10:54:49]
09/27/2017 10:57:06 updates[   229] train loss[6.83642] remaining[10:53:21]
09/27/2017 10:57:47 updates[   232] train loss[6.82049] remaining[10:51:17]
09/27/2017 10:58:35 updates[   235] train loss[6.81089] remaining[10:50:35]
09/27/2017 10:59:09 updates[   238] train loss[6.80679] remaining[10:47:26]
09/27/2017 10:59:46 updates[   241] train loss[6.79452] remaining[10:44:57]
09/27/2017 11:00:33 updates[   244] train loss[6.78039] remaining[10:44:03]
09/27/2017 11:01:07 updates[   247] train loss[6.76235] remaining[10:41:02]
09/27/2017 11:01:46 updates[   250] train loss[6.75491] remaining[10:38:54]
09/27/2017 11:02:26 updates[   253] train loss[6.74020] remaining[10:37:00]
09/27/2017 11:03:28 updates[   256] train loss[6.72735] remaining[10:38:41]
09/27/2017 11:03:58 updates[   259] train loss[6.71654] remaining[10:35:15]
09/27/2017 11:04:31 updates[   262] train loss[6.70194] remaining[10:32:21]
09/27/2017 11:05:08 updates[   265] train loss[6.69441] remaining[10:30:06]
09/27/2017 11:05:59 updates[   268] train loss[6.68501] remaining[10:29:55]
09/27/2017 11:06:34 updates[   271] train loss[6.67640] remaining[10:27:20]
09/27/2017 11:07:13 updates[   274] train loss[6.66568] remaining[10:25:27]
09/27/2017 11:07:44 updates[   277] train loss[6.65186] remaining[10:22:25]
09/27/2017 11:08:16 updates[   280] train loss[6.63599] remaining[10:19:37]
09/27/2017 11:08:49 updates[   283] train loss[6.61875] remaining[10:16:58]
09/27/2017 11:09:30 updates[   286] train loss[6.60580] remaining[10:15:33]
09/27/2017 11:10:02 updates[   289] train loss[6.58517] remaining[10:12:52]
09/27/2017 11:10:40 updates[   292] train loss[6.57638] remaining[10:10:56]
09/27/2017 11:11:14 updates[   295] train loss[6.56007] remaining[10:08:42]
09/27/2017 11:11:57 updates[   298] train loss[6.54649] remaining[10:07:29]
09/27/2017 11:12:42 updates[   301] train loss[6.53089] remaining[10:06:44]
09/27/2017 11:13:13 updates[   304] train loss[6.52235] remaining[10:04:01]
09/27/2017 11:14:18 updates[   307] train loss[6.50830] remaining[10:05:44]
09/27/2017 11:14:57 updates[   310] train loss[6.49782] remaining[10:04:10]
09/27/2017 11:15:27 updates[   313] train loss[6.48904] remaining[10:01:29]
09/27/2017 11:16:13 updates[   316] train loss[6.47548] remaining[10:00:43]
09/27/2017 11:17:03 updates[   319] train loss[6.46610] remaining[10:00:32]
09/27/2017 11:17:52 updates[   322] train loss[6.45803] remaining[10:00:19]
09/27/2017 11:18:36 updates[   325] train loss[6.45201] remaining[9:59:21]
09/27/2017 11:19:08 updates[   328] train loss[6.44802] remaining[9:56:59]
09/27/2017 11:19:53 updates[   331] train loss[6.44111] remaining[9:56:07]
09/27/2017 11:20:38 updates[   334] train loss[6.43004] remaining[9:55:19]
09/27/2017 11:21:10 updates[   337] train loss[6.42362] remaining[9:53:00]
09/27/2017 11:21:54 updates[   340] train loss[6.41626] remaining[9:52:11]
09/27/2017 11:23:22 updates[   343] train loss[6.40737] remaining[9:56:18]
09/27/2017 11:24:13 updates[   346] train loss[6.39719] remaining[9:56:09]
09/27/2017 11:24:50 updates[   349] train loss[6.38590] remaining[9:54:26]
09/27/2017 11:25:26 updates[   352] train loss[6.38185] remaining[9:52:37]
09/27/2017 11:26:03 updates[   355] train loss[6.37293] remaining[9:50:55]
09/27/2017 11:27:02 updates[   358] train loss[6.36922] remaining[9:51:39]
09/27/2017 11:27:51 updates[   361] train loss[6.36031] remaining[9:51:12]
09/27/2017 11:28:40 updates[   364] train loss[6.35120] remaining[9:50:50]
09/27/2017 11:29:31 updates[   367] train loss[6.34162] remaining[9:50:38]
09/27/2017 11:30:09 updates[   370] train loss[6.33327] remaining[9:49:04]
09/27/2017 11:31:19 updates[   373] train loss[6.32268] remaining[9:50:51]
09/27/2017 11:32:05 updates[   376] train loss[6.31354] remaining[9:50:06]
09/27/2017 11:32:37 updates[   379] train loss[6.30285] remaining[9:47:59]
09/27/2017 11:33:11 updates[   382] train loss[6.29673] remaining[9:45:58]
09/27/2017 11:33:53 updates[   385] train loss[6.28914] remaining[9:44:54]
09/27/2017 11:34:48 updates[   388] train loss[6.28428] remaining[9:45:07]
09/27/2017 11:35:18 updates[   391] train loss[6.27528] remaining[9:42:46]
09/27/2017 11:35:57 updates[   394] train loss[6.27364] remaining[9:41:26]
09/27/2017 11:36:32 updates[   397] train loss[6.26525] remaining[9:39:36]
09/27/2017 11:37:14 updates[   400] train loss[6.25546] remaining[9:38:34]
09/27/2017 11:37:48 updates[   403] train loss[6.24496] remaining[9:36:42]
09/27/2017 11:38:21 updates[   406] train loss[6.23824] remaining[9:34:48]
09/27/2017 11:39:15 updates[   409] train loss[6.23349] remaining[9:34:53]
09/27/2017 11:40:02 updates[   412] train loss[6.22745] remaining[9:34:20]
09/27/2017 11:40:53 updates[   415] train loss[6.21774] remaining[9:34:02]
09/27/2017 11:41:39 updates[   418] train loss[6.20411] remaining[9:33:25]
09/27/2017 11:42:49 updates[   421] train loss[6.19556] remaining[9:34:52]
09/27/2017 11:43:36 updates[   424] train loss[6.18140] remaining[9:34:15]
09/27/2017 11:44:06 updates[   427] train loss[6.17197] remaining[9:32:06]
09/27/2017 11:45:27 updates[   430] train loss[6.17050] remaining[9:34:27]
09/27/2017 11:46:04 updates[   433] train loss[6.16691] remaining[9:32:57]
09/27/2017 11:46:41 updates[   436] train loss[6.15790] remaining[9:31:28]
09/27/2017 11:47:19 updates[   439] train loss[6.14797] remaining[9:30:03]
09/27/2017 11:47:59 updates[   442] train loss[6.14293] remaining[9:28:50]
09/27/2017 11:48:43 updates[   445] train loss[6.13527] remaining[9:28:00]
09/27/2017 11:49:30 updates[   448] train loss[6.12973] remaining[9:27:19]
09/27/2017 11:50:07 updates[   451] train loss[6.12293] remaining[9:25:53]
09/27/2017 11:50:40 updates[   454] train loss[6.11853] remaining[9:24:07]
09/27/2017 11:51:22 updates[   457] train loss[6.10942] remaining[9:23:05]
09/27/2017 11:51:50 updates[   460] train loss[6.10149] remaining[9:20:58]
09/27/2017 11:52:25 updates[   463] train loss[6.09592] remaining[9:19:25]
09/27/2017 11:53:50 updates[   466] train loss[6.09380] remaining[9:21:47]
09/27/2017 11:55:24 updates[   469] train loss[6.08850] remaining[9:24:56]
09/27/2017 11:56:07 updates[   472] train loss[6.08078] remaining[9:23:55]
09/27/2017 11:56:43 updates[   475] train loss[6.07153] remaining[9:22:28]
09/27/2017 11:57:12 updates[   478] train loss[6.06696] remaining[9:20:24]
09/27/2017 11:57:50 updates[   481] train loss[6.05944] remaining[9:19:04]
09/27/2017 11:58:26 updates[   484] train loss[6.05205] remaining[9:17:33]
09/27/2017 11:58:53 updates[   487] train loss[6.04216] remaining[9:15:28]
09/27/2017 11:59:51 updates[   490] train loss[6.03953] remaining[9:15:37]
09/28/2017 12:01:48 updates[   493] train loss[6.03501] remaining[9:20:13]
09/28/2017 12:02:18 updates[   496] train loss[6.03110] remaining[9:18:20]
09/28/2017 12:02:52 updates[   499] train loss[6.02615] remaining[9:16:42]
09/28/2017 12:03:28 updates[   502] train loss[6.01884] remaining[9:15:15]
09/28/2017 12:04:12 updates[   505] train loss[6.01252] remaining[9:14:22]
09/28/2017 12:05:57 updates[   508] train loss[6.00593] remaining[9:17:54]
09/28/2017 12:06:45 updates[   511] train loss[5.99929] remaining[9:17:17]
09/28/2017 12:07:40 updates[   514] train loss[5.99114] remaining[9:17:09]
09/28/2017 12:08:22 updates[   517] train loss[5.98742] remaining[9:16:06]
09/28/2017 12:09:22 updates[   520] train loss[5.98286] remaining[9:16:18]
09/28/2017 12:10:20 updates[   523] train loss[5.97746] remaining[9:16:23]
09/28/2017 12:11:07 updates[   526] train loss[5.96985] remaining[9:15:40]
09/28/2017 12:12:27 updates[   529] train loss[5.96542] remaining[9:17:15]
09/28/2017 12:13:31 updates[   532] train loss[5.95868] remaining[9:17:41]
09/28/2017 12:14:13 updates[   535] train loss[5.95445] remaining[9:16:37]
09/28/2017 12:15:20 updates[   538] train loss[5.94841] remaining[9:17:11]
09/28/2017 12:16:13 updates[   541] train loss[5.94095] remaining[9:16:51]
09/28/2017 12:17:12 updates[   544] train loss[5.93623] remaining[9:16:54]
09/28/2017 12:17:54 updates[   547] train loss[5.93264] remaining[9:15:49]
09/28/2017 12:18:52 updates[   550] train loss[5.92499] remaining[9:15:49]
09/28/2017 12:20:07 updates[   553] train loss[5.91954] remaining[9:16:51]
09/28/2017 12:21:19 updates[   556] train loss[5.91539] remaining[9:17:43]
09/28/2017 12:23:57 updates[   559] train loss[5.91084] remaining[9:23:59]
09/28/2017 12:25:11 updates[   562] train loss[5.90733] remaining[9:24:54]
09/28/2017 12:26:15 updates[   565] train loss[5.90105] remaining[9:25:07]
09/28/2017 12:27:32 updates[   568] train loss[5.89897] remaining[9:26:10]
09/28/2017 12:28:33 updates[   571] train loss[5.89657] remaining[9:26:10]
09/28/2017 12:29:51 updates[   574] train loss[5.89044] remaining[9:27:12]
09/28/2017 12:30:36 updates[   577] train loss[5.88667] remaining[9:26:13]
09/28/2017 12:31:28 updates[   580] train loss[5.87957] remaining[9:25:42]
09/28/2017 12:32:32 updates[   583] train loss[5.87300] remaining[9:25:52]
09/28/2017 12:33:17 updates[   586] train loss[5.86803] remaining[9:24:52]
09/28/2017 12:34:09 updates[   589] train loss[5.86292] remaining[9:24:18]
09/28/2017 12:34:55 updates[   592] train loss[5.85918] remaining[9:23:21]
09/28/2017 12:35:41 updates[   595] train loss[5.85617] remaining[9:22:24]
09/28/2017 12:36:38 updates[   598] train loss[5.85563] remaining[9:22:07]
09/28/2017 12:37:39 updates[   601] train loss[5.85011] remaining[9:22:02]
09/28/2017 12:38:27 updates[   604] train loss[5.84624] remaining[9:21:16]
09/28/2017 12:39:43 updates[   607] train loss[5.83872] remaining[9:22:01]
09/28/2017 12:41:13 updates[   610] train loss[5.83404] remaining[9:23:37]
09/28/2017 12:42:07 updates[   613] train loss[5.83060] remaining[9:23:06]
09/28/2017 12:35:34 [program starts.]
09/28/2017 12:35:34 {'ner_size': 19, 'num_features': 4, 'eval_per_epoch': 1, 'use_qemb': True, 'epochs': 20, 'pos_dim': 12, 'log_file': 'output.log', 'batch_size': 32, 'learning_rate': 0.1, 'ner_dim': 8, 'cuda': False, 'hidden_size': 128, 'resume': '', 'momentum': 0, 'tune_partial': 1000, 'model_dir': 'models', 'pos': True, 'concat_rnn_layers': True, 'data_file': 'SQuAD/data.msgpack', 'reduce_lr': 0.0, 'ner': True, 'rnn_type': 'lstm', 'pos_size': 56, 'grad_clipping': 10, 'weight_decay': 0, 'rnn_padding': False, 'dropout_emb': 0.3, 'max_len': 15, 'question_layers': 3, 'dropout_rnn': 0.3, 'log_per_updates': 3, 'question_merge': 'self_attn', 'dropout_rnn_output': True, 'seed': 411, 'optimizer': 'adamax', 'fix_embeddings': False, 'doc_layers': 3, 'save_last_only': False, 'resume_options': False}
09/28/2017 12:35:58 [Data loaded.]
09/28/2017 12:36:00 Epoch 1
09/28/2017 12:36:32 updates[     1] train loss[9.96538] remaining[23:42:25]
09/28/2017 12:37:56 [program starts.]
09/28/2017 12:37:56 {'doc_layers': 3, 'ner_dim': 8, 'pos_size': 56, 'resume_options': False, 'ner': False, 'question_merge': 'self_attn', 'reduce_lr': 0.0, 'max_len': 15, 'dropout_rnn_output': True, 'dropout_emb': 0.3, 'tune_partial': 1000, 'fix_embeddings': False, 'pos_dim': 12, 'eval_per_epoch': 1, 'question_layers': 3, 'epochs': 20, 'hidden_size': 128, 'learning_rate': 0.1, 'use_qemb': True, 'rnn_padding': False, 'data_file': 'SQuAD/data.msgpack', 'resume': '', 'model_dir': 'models', 'log_file': 'output.log', 'weight_decay': 0, 'pos': False, 'seed': 411, 'concat_rnn_layers': True, 'num_features': 4, 'cuda': False, 'optimizer': 'adamax', 'log_per_updates': 3, 'grad_clipping': 10, 'batch_size': 32, 'save_last_only': False, 'ner_size': 19, 'dropout_rnn': 0.3, 'momentum': 0, 'rnn_type': 'lstm'}
09/28/2017 12:38:25 [Data loaded.]
09/28/2017 12:38:27 Epoch 1
09/28/2017 12:39:05 updates[     1] train loss[9.94654] remaining[1 day, 4:32:10]
09/28/2017 12:39:54 updates[     4] train loss[9.45673] remaining[16:09:21]
09/28/2017 12:40:59 updates[     7] train loss[9.31686] remaining[16:12:57]
09/28/2017 02:26:40 [program starts.]
09/28/2017 02:26:40 {'log_per_updates': 3, 'pos': True, 'fix_embeddings': False, 'doc_layers': 3, 'question_layers': 3, 'dropout_rnn_output': True, 'save_last_only': False, 'batch_size': 32, 'model_dir': 'models', 'rnn_type': 'lstm', 'tune_partial': 1000, 'max_len': 15, 'optimizer': 'adamax', 'dropout_rnn': 0.3, 'learning_rate': 0.1, 'resume_options': False, 'ner_size': 19, 'cuda': False, 'pos_size': 56, 'eval_per_epoch': 1, 'question_merge': 'self_attn', 'seed': 411, 'hidden_size': 128, 'use_qemb': True, 'num_features': 4, 'ner_dim': 8, 'weight_decay': 0, 'momentum': 0, 'log_file': 'output.log', 'dropout_emb': 0.3, 'data_file': 'SQuAD/data.msgpack', 'rnn_padding': False, 'ner': True, 'epochs': 20, 'pos_dim': 12, 'grad_clipping': 10, 'resume': '', 'reduce_lr': 0.0, 'concat_rnn_layers': True}
09/28/2017 02:27:05 [Data loaded.]
09/28/2017 02:27:08 Epoch 1
09/28/2017 02:27:44 [program starts.]
09/28/2017 02:27:44 {'cuda': False, 'batch_size': 32, 'pos_dim': 12, 'pos': True, 'seed': 411, 'doc_layers': 3, 'max_len': 15, 'use_qemb': True, 'ner_size': 19, 'grad_clipping': 10, 'question_layers': 3, 'num_features': 4, 'concat_rnn_layers': True, 'epochs': 20, 'log_file': 'output.log', 'ner': True, 'reduce_lr': 0.0, 'hidden_size': 128, 'model_dir': 'models', 'dropout_rnn_output': True, 'fix_embeddings': False, 'dropout_rnn': 0.3, 'data_file': 'SQuAD/data.msgpack', 'optimizer': 'adamax', 'question_merge': 'self_attn', 'log_per_updates': 3, 'pos_size': 56, 'rnn_type': 'lstm', 'learning_rate': 0.1, 'dropout_emb': 0.3, 'resume_options': False, 'ner_dim': 8, 'resume': '', 'momentum': 0, 'weight_decay': 0, 'eval_per_epoch': 1, 'rnn_padding': False, 'save_last_only': False, 'tune_partial': 1000}
09/28/2017 02:28:09 [Data loaded.]
09/28/2017 02:28:11 Epoch 1
09/28/2017 02:28:49 updates[     1] train loss[9.96538] remaining[1 day, 4:05:45]
09/28/2017 02:29:36 updates[     4] train loss[9.31764] remaining[15:51:14]
09/28/2017 02:30:07 [program starts.]
09/28/2017 02:30:07 {'dropout_rnn_output': True, 'num_features': 4, 'resume': '', 'pos_dim': 12, 'pos_size': 56, 'resume_options': False, 'ner_size': 19, 'question_layers': 3, 'tune_partial': 1000, 'dropout_emb': 0.3, 'epochs': 20, 'rnn_type': 'lstm', 'save_last_only': False, 'max_len': 15, 'momentum': 0, 'question_merge': 'self_attn', 'log_file': 'output.log', 'weight_decay': 0, 'model_dir': 'models', 'grad_clipping': 10, 'batch_size': 32, 'use_qemb': True, 'rnn_padding': False, 'cuda': False, 'dropout_rnn': 0.3, 'seed': 411, 'optimizer': 'adamax', 'pos': False, 'learning_rate': 0.1, 'data_file': 'SQuAD/data.msgpack', 'hidden_size': 128, 'concat_rnn_layers': True, 'fix_embeddings': False, 'log_per_updates': 3, 'doc_layers': 3, 'reduce_lr': 0.0, 'ner': False, 'ner_dim': 8, 'eval_per_epoch': 1}
09/28/2017 02:30:34 [Data loaded.]
09/28/2017 02:30:36 Epoch 1
09/28/2017 02:31:11 updates[     1] train loss[9.94654] remaining[1 day, 2:19:27]
09/28/2017 02:31:54 updates[     4] train loss[9.45673] remaining[14:33:26]
09/28/2017 02:32:54 updates[     7] train loss[9.31686] remaining[14:42:39]
09/28/2017 02:33:46 updates[    10] train loss[9.23356] remaining[14:09:06]
09/28/2017 02:34:27 updates[    13] train loss[9.17769] remaining[13:15:00]
09/28/2017 05:02:50 [program starts.]
09/28/2017 05:02:50 {'eval_per_epoch': 1, 'pos_dim': 12, 'pos': False, 'resume_options': False, 'tune_partial': 1000, 'model_dir': 'models', 'rnn_type': 'lstm', 'dropout_rnn': 0.3, 'epochs': 20, 'fix_embeddings': False, 'rnn_padding': False, 'num_features': 4, 'max_len': 15, 'question_merge': 'self_attn', 'reduce_lr': 0.0, 'save_last_only': False, 'log_per_updates': 3, 'seed': 411, 'concat_rnn_layers': True, 'doc_layers': 3, 'question_layers': 3, 'ner': False, 'weight_decay': 0, 'batch_size': 32, 'ner_size': 19, 'optimizer': 'adamax', 'learning_rate': 0.1, 'cuda': False, 'resume': '', 'grad_clipping': 10, 'features': False, 'ner_dim': 8, 'dropout_emb': 0.3, 'dropout_rnn_output': True, 'momentum': 0, 'pos_size': 56, 'log_file': 'output.log', 'hidden_size': 128, 'use_qemb': True, 'data_file': 'SQuAD/data.msgpack'}
09/28/2017 05:03:05 [Data loaded.]
09/28/2017 05:03:07 Epoch 1
09/28/2017 05:04:29 [program starts.]
09/28/2017 05:04:29 {'learning_rate': 0.1, 'dropout_rnn': 0.3, 'dropout_rnn_output': True, 'eval_per_epoch': 1, 'seed': 411, 'save_last_only': False, 'ner_dim': 8, 'pos_dim': 12, 'ner_size': 19, 'pos': False, 'rnn_type': 'lstm', 'cuda': False, 'doc_layers': 3, 'dropout_emb': 0.3, 'rnn_padding': False, 'optimizer': 'adamax', 'weight_decay': 0, 'question_layers': 3, 'features': False, 'num_features': 4, 'fix_embeddings': False, 'use_qemb': True, 'momentum': 0, 'reduce_lr': 0.0, 'model_dir': 'models', 'pos_size': 56, 'batch_size': 32, 'max_len': 15, 'data_file': 'SQuAD/data.msgpack', 'resume': '', 'concat_rnn_layers': True, 'resume_options': False, 'hidden_size': 128, 'tune_partial': 1000, 'log_per_updates': 3, 'epochs': 20, 'question_merge': 'self_attn', 'grad_clipping': 10, 'log_file': 'output.log', 'ner': False}
09/28/2017 05:04:43 [Data loaded.]
09/28/2017 05:04:45 Epoch 1
09/28/2017 05:04:59 [program starts.]
09/28/2017 05:04:59 {'eval_per_epoch': 1, 'pos': False, 'learning_rate': 0.1, 'resume_options': False, 'seed': 411, 'features': False, 'doc_layers': 3, 'weight_decay': 0, 'ner_dim': 8, 'resume': '', 'save_last_only': False, 'momentum': 0, 'batch_size': 32, 'dropout_rnn_output': True, 'num_features': 4, 'optimizer': 'adamax', 'pos_dim': 12, 'reduce_lr': 0.0, 'log_per_updates': 3, 'cuda': False, 'pos_size': 56, 'hidden_size': 128, 'ner': False, 'question_merge': 'self_attn', 'rnn_padding': False, 'use_qemb': True, 'data_file': 'SQuAD/data.msgpack', 'question_layers': 3, 'fix_embeddings': False, 'rnn_type': 'lstm', 'ner_size': 19, 'tune_partial': 1000, 'concat_rnn_layers': True, 'model_dir': 'models', 'log_file': 'output.log', 'epochs': 20, 'dropout_rnn': 0.3, 'dropout_emb': 0.3, 'grad_clipping': 10, 'max_len': 15}
09/28/2017 05:05:13 [Data loaded.]
09/28/2017 05:05:15 Epoch 1
09/28/2017 05:07:06 [program starts.]
09/28/2017 05:07:06 {'question_layers': 3, 'pos_size': 56, 'eval_per_epoch': 1, 'doc_layers': 3, 'tune_partial': 1000, 'max_len': 15, 'num_features': 4, 'save_last_only': False, 'batch_size': 32, 'weight_decay': 0, 'learning_rate': 0.1, 'log_file': 'output.log', 'dropout_emb': 0.3, 'epochs': 20, 'momentum': 0, 'concat_rnn_layers': True, 'question_merge': 'self_attn', 'rnn_padding': False, 'pos': False, 'features': False, 'resume': '', 'hidden_size': 128, 'ner_dim': 8, 'fix_embeddings': False, 'cuda': False, 'reduce_lr': 0.0, 'seed': 411, 'ner': False, 'ner_size': 19, 'resume_options': False, 'dropout_rnn_output': True, 'dropout_rnn': 0.3, 'rnn_type': 'lstm', 'data_file': 'SQuAD/data.msgpack', 'model_dir': 'models', 'optimizer': 'adamax', 'pos_dim': 12, 'use_qemb': True, 'grad_clipping': 10, 'log_per_updates': 3}
09/28/2017 05:07:20 [Data loaded.]
09/28/2017 05:07:22 Epoch 1
09/28/2017 05:08:30 [program starts.]
09/28/2017 05:08:30 {'hidden_size': 128, 'epochs': 20, 'max_len': 15, 'eval_per_epoch': 1, 'resume': '', 'tune_partial': 1000, 'ner': False, 'model_dir': 'models', 'learning_rate': 0.1, 'dropout_rnn': 0.3, 'cuda': False, 'dropout_emb': 0.3, 'reduce_lr': 0.0, 'ner_dim': 8, 'pos_dim': 12, 'log_file': 'output.log', 'optimizer': 'adamax', 'doc_layers': 3, 'momentum': 0, 'question_merge': 'self_attn', 'log_per_updates': 3, 'question_layers': 3, 'rnn_padding': False, 'pos_size': 56, 'resume_options': False, 'batch_size': 32, 'concat_rnn_layers': True, 'use_qemb': True, 'fix_embeddings': False, 'ner_size': 19, 'data_file': 'SQuAD/data.msgpack', 'dropout_rnn_output': True, 'features': False, 'save_last_only': False, 'weight_decay': 0, 'seed': 411, 'grad_clipping': 10, 'rnn_type': 'lstm', 'num_features': 4, 'pos': False}
09/28/2017 05:08:44 [Data loaded.]
09/28/2017 05:08:46 Epoch 1
09/28/2017 05:09:19 updates[     1] train loss[9.97257] remaining[1 day, 0:18:40]
09/28/2017 05:10:01 updates[     4] train loss[9.51378] remaining[13:55:47]
09/28/2017 05:11:02 updates[     7] train loss[9.39279] remaining[14:31:17]
09/28/2017 05:12:00 updates[    10] train loss[9.33529] remaining[14:26:52]
09/28/2017 05:12:44 updates[    13] train loss[9.30907] remaining[13:38:13]
09/28/2017 05:13:46 updates[    16] train loss[9.21045] remaining[13:57:46]
09/28/2017 05:17:48 [program starts.]
09/28/2017 05:17:48 {'batch_size': 32, 'reduce_lr': 0.0, 'log_file': 'output.log', 'epochs': 20, 'max_len': 15, 'eval_per_epoch': 1, 'ner_size': 19, 'features': False, 'pos_dim': 12, 'doc_layers': 3, 'question_layers': 3, 'save_last_only': False, 'log_per_updates': 3, 'optimizer': 'adamax', 'concat_rnn_layers': True, 'pos_size': 56, 'dropout_rnn': 0.3, 'data_file': 'SQuAD/data.msgpack', 'rnn_padding': False, 'grad_clipping': 10, 'weight_decay': 0, 'dropout_rnn_output': True, 'use_qemb': True, 'momentum': 0, 'resume_options': False, 'cuda': False, 'ner_dim': 8, 'rnn_type': 'lstm', 'seed': 411, 'hidden_size': 128, 'ner': False, 'tune_partial': 1000, 'dropout_emb': 0.3, 'resume': '', 'num_features': 4, 'model_dir': 'models', 'fix_embeddings': False, 'question_merge': 'self_attn', 'learning_rate': 0.1, 'pos': False}
09/28/2017 05:18:03 [Data loaded.]
09/28/2017 05:18:07 Epoch 1
09/28/2017 05:18:44 updates[     1] train loss[9.97257] remaining[1 day, 3:09:50]
09/28/2017 05:19:28 updates[     4] train loss[9.51378] remaining[15:01:54]
09/28/2017 05:20:27 updates[     7] train loss[9.39279] remaining[14:55:38]
09/28/2017 05:22:31 updates[    10] train loss[9.33529] remaining[19:39:28]
09/28/2017 05:23:57 updates[    13] train loss[9.30907] remaining[20:01:55]
09/28/2017 05:25:00 updates[    16] train loss[9.21045] remaining[19:11:58]
09/28/2017 05:25:56 updates[    19] train loss[9.13767] remaining[18:19:57]
