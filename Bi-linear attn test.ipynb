{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasonet evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Части, специфичные для Reasonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:All works\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger.info('All works')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from overrides import overrides\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "from allennlp.common import Params\n",
    "#from allennlp.modules.similarity_functions.similarity_function import SimilarityFunction\n",
    "from allennlp.modules.similarity_function import SimilarityFunction\n",
    "from allennlp.nn import Activation\n",
    "from torch.autograd import Variable\n",
    "from allennlp.modules.similarity_functions.bilinear import BilinearSimilarity\n",
    "from allennlp.modules.attention import Attention\n",
    "from allennlp.nn.util import weighted_sum\n",
    "import allennlp.nn.util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CUDA_wrapper(tensor):\n",
    "    if torch.cuda.is_available():\n",
    "        return tensor.cuda()\n",
    "    else:\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batchwise_index(array_batch, index_batch):\n",
    "    assert index_batch.dim() == 1\n",
    "    assert array_batch.size(0) == index_batch.size(0)\n",
    "    index_batch_one_hot = CUDA_wrapper(\n",
    "        autograd.Variable(torch.ByteTensor(array_batch.size()).zero_(), requires_grad=False)\n",
    "    )\n",
    "    index_batch_one_hot.scatter_(1, index_batch.data.unsqueeze(-1), 1)\n",
    "    return array_batch[index_batch_one_hot]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention over memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionCoefProvider(object):\n",
    "    \"\"\"\n",
    "    Attention coef provider\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 similarity_function: SimilarityFunction,\n",
    "                 normalize: bool) -> None:\n",
    "        self._similarity_function = similarity_function\n",
    "        self._attention = Attention(similarity_function, normalize=normalize)\n",
    "        super(AttentionCoefProvider, self).__init__()\n",
    "        \n",
    "    def forward(self, state: torch.Tensor, memory: torch.Tensor) -> torch.Tensor:\n",
    "        return self._attention(state, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttentionOverMemory(object):\n",
    "    \"\"\"\n",
    "    Attention over memory\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 coef_provider: AttentionCoefProvider) -> None:\n",
    "        self._coef_provider = coef_provider\n",
    "        super(AttentionOverMemory, self).__init__()\n",
    "        \n",
    "    def forward(self, state: torch.Tensor, memory: torch.Tensor) -> torch.Tensor:\n",
    "        attn_coefficients = self._coef_provider.forward(state, memory)\n",
    "        return weighted_sum(memory, attn_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AttentionProvider = AttentionOverMemory(AttentionCoefProvider(BilinearSimilarity(300,300), True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StateController(object):\n",
    "\n",
    "    def __init__(self, module: torch.nn.modules.RNNCell) -> None:\n",
    "        super(StateController, self).__init__()\n",
    "        self._module = module\n",
    "        self.hidden_state = None\n",
    "        try:\n",
    "            if not self._module.batch_first:\n",
    "                raise ConfigurationError(\"Our encoder semantics assumes batch is always first!\")\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._module.input_size\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        return self._module.hidden_size\n",
    "\n",
    "    def forward(self,  # pylint: disable=arguments-differ\n",
    "                inputs: torch.Tensor,\n",
    "                hidden_state: torch.Tensor = None) -> torch.Tensor:\n",
    "\n",
    "        if hidden_state is None:\n",
    "            if not self.hidden_state is None:\n",
    "                hidden_state = self.hidden_state\n",
    "            else:\n",
    "                raise ConfigurationError(\"Hidden state must be specified!\")\n",
    "                \n",
    "        self.hidden_state = self._module(inputs, hidden_state)\n",
    "        return self.hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_controller = StateController(torch.nn.GRUCell(300, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Termination gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TerminationGate(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim: int) -> None:\n",
    "        super(TerminationGate, self).__init__()\n",
    "        self._hiden_dim = hidden_dim\n",
    "        self.linear = torch.nn.Linear(hidden_dim, 2)\n",
    "        \n",
    "    def forward(self, hidden_state: torch.Tensor):\n",
    "        tensor_output = util.last_dim_softmax(self.linear(hidden_state))\n",
    "        last_dim = tensor_output.dim() - 1\n",
    "        return torch.chunk(tensor_output, 2, last_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reasonet inner controller logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReasoningProcess(object):\n",
    "    \n",
    "    def __init__(self, timesteps:int,\n",
    "                 attention_provider: AttentionProvider,\n",
    "                 state_controller: StateController) -> None:\n",
    "        \n",
    "        self._timesteps = timesteps\n",
    "        self._attention_provider = attention_provider\n",
    "        self._state_controller = state_controller\n",
    "        \n",
    "    def forward(self, initial_hidden_state: torch.Tensor,\n",
    "                memory: torch.Tensor):\n",
    "        \n",
    "        # use initial_hidden state to perform first state of computations\n",
    "        attn = self._attention_provider.forward(initial_hidden_state, memory)\n",
    "        hidden_state = self._state_controller.forward(attn, initial_hidden_state)\n",
    "        \n",
    "        if self._timesteps > 1:\n",
    "            for i in range(self._timesteps-1):\n",
    "                attn = self._attention_provider.forward(hidden_state, memory)\n",
    "                hidden_state = self._state_controller.forward(attn)\n",
    "                \n",
    "        return hidden_state\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReasoningProcessStep(object):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 attention_provider: AttentionProvider,\n",
    "                 state_controller: StateController) -> None:\n",
    "        \n",
    "        self._attention_provider = attention_provider\n",
    "        self._state_controller = state_controller\n",
    "        \n",
    "    def forward(self, initial_hidden_state: torch.Tensor,\n",
    "                memory: torch.Tensor):\n",
    "        \n",
    "        # use initial_hidden state to perform first state of computations\n",
    "        attn = self._attention_provider.forward(initial_hidden_state, memory)\n",
    "        hidden_state = self._state_controller.forward(attn, initial_hidden_state)\n",
    "        \n",
    "        return hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reasoner = ReasoningProcess(5, \n",
    "                            AttentionOverMemory(AttentionCoefProvider(BilinearSimilarity(300,300), True)),\n",
    "                            StateController(torch.nn.GRUCell(300, 300)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2SeqWrapper, that returns (all_states, last_state) tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.modules.seq2seq_encoders.seq2seq_encoder import Seq2SeqEncoder\n",
    "from allennlp.nn.util import sort_batch_by_length, get_lengths_from_binary_sequence_mask\n",
    "\n",
    "\n",
    "class PytorchLastStateSeq2SeqWrapper(Seq2SeqEncoder):\n",
    "    \"\"\"\n",
    "    Pytorch's RNNs have two outputs: the hidden state for every time step, and the hidden state at\n",
    "    the last time step for every layer.  We just want the first one as a single output.  This\n",
    "    wrapper pulls out that output, and adds a :func:`get_output_dim` method, which is useful if you\n",
    "    want to, e.g., define a linear + softmax layer on top of this to get some distribution over a\n",
    "    set of labels.  The linear layer needs to know its input dimension before it is called, and you\n",
    "    can get that from ``get_output_dim``.\n",
    "\n",
    "    In order to be wrapped with this wrapper, a class must have the following members:\n",
    "\n",
    "        - ``self.input_size: int``\n",
    "        - ``self.hidden_size: int``\n",
    "        - ``def forward(inputs: PackedSequence, hidden_state: torch.autograd.Variable) ->\n",
    "          Tuple[PackedSequence, torch.autograd.Variable]``.\n",
    "        - ``self.bidirectional: bool`` (optional)\n",
    "\n",
    "    This is what pytorch's RNN's look like - just make sure your class looks like those, and it\n",
    "    should work.\n",
    "\n",
    "    Note that we *require* you to pass sequence lengths when you call this module, to avoid subtle\n",
    "    bugs around masking.  If you already have a ``PackedSequence`` you can pass ``None`` as the\n",
    "    second parameter.\n",
    "    \"\"\"\n",
    "    def __init__(self, module: torch.nn.modules.RNNBase) -> None:\n",
    "        super(PytorchLastStateSeq2SeqWrapper, self).__init__()\n",
    "        self._module = module\n",
    "        try:\n",
    "            if not self._module.batch_first:\n",
    "                raise ConfigurationError(\"Our encoder semantics assumes batch is always first!\")\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    def get_input_dim(self) -> int:\n",
    "        return self._module.input_size\n",
    "\n",
    "    def get_output_dim(self) -> int:\n",
    "        try:\n",
    "            is_bidirectional = self._module.bidirectional\n",
    "        except AttributeError:\n",
    "            is_bidirectional = False\n",
    "        return self._module.hidden_size * (2 if is_bidirectional else 1)\n",
    "\n",
    "    def forward(self,  # pylint: disable=arguments-differ\n",
    "                inputs: torch.Tensor,\n",
    "                mask: torch.Tensor,\n",
    "                hidden_state: torch.Tensor = None) -> torch.Tensor:\n",
    "\n",
    "        if mask is None:\n",
    "            return self._module(inputs, hidden_state)[0]\n",
    "        sequence_lengths = get_lengths_from_binary_sequence_mask(mask)\n",
    "        sorted_inputs, sorted_sequence_lengths, restoration_indices = sort_batch_by_length(inputs,\n",
    "                                                                                           sequence_lengths)\n",
    "        packed_sequence_input = pack_padded_sequence(sorted_inputs,\n",
    "                                                     sorted_sequence_lengths.data.tolist(),\n",
    "                                                     batch_first=True)\n",
    "\n",
    "        # Actually call the module on the sorted PackedSequence.\n",
    "        packed_sequence_output, state = self._module(packed_sequence_input, hidden_state)\n",
    "\n",
    "        # Deal with the fact the LSTM state is a tuple of (state, memory).\n",
    "        if isinstance(state, tuple):\n",
    "            state = state[0]\n",
    "\n",
    "        # Restore the original indices and return the final state of the\n",
    "        # top layer. Pytorch's recurrent layers return state in the form\n",
    "        # (num_layers * num_directions, batch_size, hidden_size) regardless\n",
    "        # of the 'batch_first' flag, so we transpose, extract the relevant\n",
    "        # layer state (both forward and backward if using bidirectional layers)\n",
    "        # and return them as a single (batch_size, self.get_output_dim()) tensor.\n",
    "\n",
    "        # now of shape: (batch_size, num_layers * num_directions, hidden_size).\n",
    "        unsorted_state = state.transpose(0, 1).index_select(0, restoration_indices)\n",
    "\n",
    "        # Extract the last hidden vector, including both forward and backward states\n",
    "        # if the cell is bidirectional. Then reshape by concatenation (in the case\n",
    "        # we have bidirectional states) or just squash the 1st dimension in the non-\n",
    "        # bidirectional case. Return tensor has shape (batch_size, hidden_size * num_directions).\n",
    "        try:\n",
    "            last_state_index = 2 if self._module.bidirectional else 1\n",
    "        except AttributeError:\n",
    "            last_state_index = 1\n",
    "        last_layer_state = unsorted_state[:, -last_state_index:, :]\n",
    "\n",
    "        unpacked_sequence_tensor, _ = pad_packed_sequence(packed_sequence_output, batch_first=True)\n",
    "        # Restore the original indices and return the sequence.\n",
    "        return unpacked_sequence_tensor.index_select(0, restoration_indices), last_layer_state.contiguous().view([-1, self.get_output_dim()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Type\n",
    "\n",
    "import torch\n",
    "\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.modules.augmented_lstm import AugmentedLstm\n",
    "#from allennlp.modules.seq2seq_encoders.intra_sentence_attention import IntraSentenceAttentionEncoder\n",
    "from allennlp.modules.seq2seq_encoders.pytorch_seq2seq_wrapper import PytorchSeq2SeqWrapper\n",
    "#from allennlp.modules.seq2seq_encoders.pytorch_last_state_seq2seq_wrapper import PytorchLastStateSeq2SeqWrapper\n",
    "from allennlp.modules.seq2seq_encoders.seq2seq_encoder import Seq2SeqEncoder\n",
    "from allennlp.modules.stacked_alternating_lstm import StackedAlternatingLstm\n",
    "\n",
    "class Seq2SeqWrapperWithLastState:\n",
    "    \"\"\"\n",
    "    For :class:`Registrable` we need to have a ``Type[Seq2SeqEncoder]`` as the value registered for each\n",
    "    key.  What that means is that we need to be able to ``__call__`` these values (as is done with\n",
    "    ``__init__`` on the class), and be able to call ``from_params()`` on the value.\n",
    "\n",
    "    In order to accomplish this, we have two options: (1) we create a ``Seq2SeqEncoder`` class for\n",
    "    all of pytorch's RNN modules individually, with our own parallel classes that we register in\n",
    "    the registry; or (2) we wrap pytorch's RNNs with something that `mimics` the required\n",
    "    API.  We've gone with the second option here.\n",
    "\n",
    "    This is a two-step approach: first, we have the :class:`PytorchSeq2SeqWrapper` class that handles\n",
    "    the interface between a pytorch RNN and our ``Seq2SeqEncoder`` API.  Our ``PytorchSeq2SeqWrapper``\n",
    "    takes an instantiated pytorch RNN and just does some interface changes.  Second, we need a way\n",
    "    to create one of these ``PytorchSeq2SeqWrappers``, with an instantiated pytorch RNN, from the\n",
    "    registry.  That's what this ``_Wrapper`` does.  The only thing this class does is instantiate\n",
    "    the pytorch RNN in a way that's compatible with ``Registrable``, then pass it off to the\n",
    "    ``PytorchSeq2SeqWrapper`` class.\n",
    "\n",
    "    When you instantiate a ``_Wrapper`` object, you give it an ``RNNBase`` subclass, which we save\n",
    "    to ``self``.  Then when called (as if we were instantiating an actual encoder with\n",
    "    ``Encoder(**params)``, or with ``Encoder.from_params(params)``), we pass those parameters\n",
    "    through to the ``RNNBase`` constructor, then pass the instantiated pytorch RNN to the\n",
    "    ``PytorchSeq2SeqWrapper``.  This lets us use this class in the registry and have everything just\n",
    "    work.\n",
    "    \"\"\"\n",
    "    PYTORCH_MODELS = [torch.nn.GRU, torch.nn.LSTM, torch.nn.RNN]\n",
    "\n",
    "    def __init__(self, module_class: Type[torch.nn.modules.RNNBase], return_last_state=False) -> None:\n",
    "        self._return_last_state = return_last_state\n",
    "        self._module_class = module_class\n",
    "\n",
    "    def __call__(self, **kwargs) -> PytorchSeq2SeqWrapper:\n",
    "        return self.from_params(Params(kwargs))\n",
    "\n",
    "    def from_params(self, params: Params) -> PytorchSeq2SeqWrapper:\n",
    "        if not params.pop('batch_first', True):\n",
    "            raise ConfigurationError(\"Our encoder semantics assumes batch is always first!\")\n",
    "        if self._module_class in self.PYTORCH_MODELS:\n",
    "            params['batch_first'] = True\n",
    "        module = self._module_class(**params.as_dict())\n",
    "        if not self._return_last_state:\n",
    "            return PytorchSeq2SeqWrapper(module)\n",
    "        else:\n",
    "            return PytorchLastStateSeq2SeqWrapper(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Seq2SeqWrapperWithLastState at 0x7fc22c979e80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Seq2SeqEncoder.register(\"l_lstm\")(Seq2SeqWrapperWithLastState(torch.nn.LSTM, return_last_state=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasonet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from allennlp.common import Params\n",
    "import pyhocon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "{\n",
    "  \"dataset_reader\": {\n",
    "    \"type\": \"squad\",\n",
    "    \"token_indexers\": {\n",
    "      \"tokens\": {\n",
    "        \"type\": \"single_id\",\n",
    "        \"lowercase_tokens\": true\n",
    "      },\n",
    "      \"token_characters\": {\n",
    "        \"type\": \"characters\",\n",
    "        \"character_tokenizer\": {\n",
    "          \"byte_encoding\": \"utf-8\",\n",
    "          \"start_tokens\": [259],\n",
    "          \"end_tokens\": [260]\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"train_data_path\": \"./squad/train-v1.1.json\",\n",
    "  \"validation_data_path\": \"./squad/dev-v1.1.json\",\n",
    "  \"model\": {\n",
    "    \"type\": \"reasonet_dev\",\n",
    "    \"text_field_embedder\": {\n",
    "      \"tokens\": {\n",
    "        \"type\": \"embedding\",\n",
    "        \"pretrained_file\": \"./glove/glove.6B.100d.txt.gz\",\n",
    "        \"embedding_dim\": 100,\n",
    "        \"trainable\": false\n",
    "      },\n",
    "      \"token_characters\": {\n",
    "        \"type\": \"character_encoding\",\n",
    "        \"embedding\": {\n",
    "          \"num_embeddings\": 262,\n",
    "          \"embedding_dim\": 16\n",
    "        },\n",
    "        \"encoder\": {\n",
    "          \"type\": \"cnn\",\n",
    "          \"embedding_dim\": 16,\n",
    "          \"num_filters\": 100,\n",
    "          \"ngram_filter_sizes\": [5]\n",
    "        },\n",
    "        \"dropout\": 0.2\n",
    "      }\n",
    "    },\n",
    "    \"num_highway_layers\": 2,\n",
    "    \"state_controller\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 200,\n",
    "      \"hidden_size\": 100,\n",
    "      \"num_layers\": 1,\n",
    "      \"dropout\": 0.2\n",
    "    },\n",
    "    \"phrase_layer\": {\n",
    "      \"type\": \"l_lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 200,\n",
    "      \"hidden_size\": 100,\n",
    "      \"num_layers\": 1,\n",
    "      \"dropout\": 0.2\n",
    "    },\n",
    "    \"similarity_function\": {\n",
    "      \"type\": \"linear\",\n",
    "      \"combination\": \"x,y,x*y\",\n",
    "      \"tensor_1_dim\": 200,\n",
    "      \"tensor_2_dim\": 200\n",
    "    },\n",
    "    \"modeling_layer\": {\n",
    "      \"type\": \"lstm\",\n",
    "      \"bidirectional\": true,\n",
    "      \"input_size\": 800,\n",
    "      \"hidden_size\": 100,\n",
    "      \"num_layers\": 2,\n",
    "      \"dropout\": 0.2\n",
    "    },\n",
    "    \"dropout\": 0.2\n",
    "  },\n",
    "  \"iterator\": {\n",
    "    \"type\": \"bucket\",\n",
    "    \"sorting_keys\": [[\"passage\", \"num_tokens\"], [\"question\", \"num_tokens\"]],\n",
    "    \"batch_size\": 40\n",
    "  },\n",
    "  \"trainer\": {\n",
    "    \"num_epochs\": 100,\n",
    "    \"grad_norm\": 5.0,\n",
    "    \"patience\": 10,\n",
    "    \"validation_metric\": \"+em\",\n",
    "    \"cuda_device\": 0,\n",
    "    \"learning_rate_scheduler\":  {\n",
    "      \"type\": \"reduce_on_plateau\",\n",
    "      \"factor\": 0.5,\n",
    "      \"mode\": \"max\",\n",
    "      \"patience\": 2,\n",
    "\n",
    "    },\n",
    "    \"no_tqdm\": true,\n",
    "    \"optimizer\": {\n",
    "      \"type\": \"adam\",\n",
    "      \"betas\": [0.9, 0.9]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = Params(pyhocon.ConfigFactory.parse_string(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<allennlp.common.params.Params at 0x7fc22c93c4a8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reasonet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "from torch.nn.functional import nll_loss\n",
    "\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.modules import Highway, MatrixAttention\n",
    "from allennlp.modules import Seq2SeqEncoder, SimilarityFunction, TimeDistributed, TextFieldEmbedder\n",
    "from allennlp.nn import util\n",
    "from allennlp.nn.initializers import InitializerApplicator\n",
    "from allennlp.training.regularizers import RegularizerApplicator\n",
    "from allennlp.training.metrics import BooleanAccuracy, CategoricalAccuracy\n",
    "# Should import this, but can't:\n",
    "#from allennlp.training.metrics import SquadEmAndF1\n",
    "from allennlp.modules.attention import Attention\n",
    "from allennlp.modules.similarity_functions.bilinear import BilinearSimilarity\n",
    "from allennlp.nn.util import weighted_sum\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "from overrides import overrides\n",
    "\n",
    "from allennlp.common import squad_eval\n",
    "from allennlp.training.metrics.metric import Metric\n",
    "\n",
    "\n",
    "@Metric.register(\"squad\")\n",
    "class SquadEmAndF1(Metric):\n",
    "    \"\"\"\n",
    "    This :class:`Metric` takes the best span string computed by a model, along with the answer\n",
    "    strings labeled in the data, and computed exact match and F1 score using the official SQuAD\n",
    "    evaluation script.\n",
    "    \"\"\"\n",
    "    def __init__(self) -> None:\n",
    "        self._total_em = 0.0\n",
    "        self._total_f1 = 0.0\n",
    "        self._count = 0\n",
    "\n",
    "    @overrides\n",
    "    def __call__(self, best_span_string, answer_strings):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        value : ``float``\n",
    "            The value to average.\n",
    "        \"\"\"\n",
    "        exact_match = squad_eval.metric_max_over_ground_truths(\n",
    "                squad_eval.exact_match_score,\n",
    "                best_span_string,\n",
    "                answer_strings)\n",
    "        f1_score = squad_eval.metric_max_over_ground_truths(\n",
    "                squad_eval.f1_score,\n",
    "                best_span_string,\n",
    "                answer_strings)\n",
    "        self._total_em += exact_match\n",
    "        self._total_f1 += f1_score\n",
    "        self._count += 1\n",
    "\n",
    "    @overrides\n",
    "    def get_metric(self, reset: bool = False) -> Tuple[float, float]:\n",
    "        \"\"\"\n",
    "        Returns\n",
    "        -------\n",
    "        Average exact match and F1 score (in that order) as computed by the official SQuAD script\n",
    "        over all inputs.\n",
    "        \"\"\"\n",
    "        exact_match = self._total_em / self._count if self._count > 0 else 0\n",
    "        f1_score = self._total_f1 / self._count if self._count > 0 else 0\n",
    "        if reset:\n",
    "            self.reset()\n",
    "        return exact_match, f1_score\n",
    "\n",
    "    @overrides\n",
    "    def reset(self):\n",
    "        self._total_em = 0.0\n",
    "        self._total_f1 = 0.0\n",
    "        self._count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@Model.register(\"reasonet_dev\")\n",
    "class Reasonet(Model):\n",
    "    \"\"\"\n",
    "    This class implements Minjoon Seo's `Bidirectional Attention Flow model\n",
    "    <https://www.semanticscholar.org/paper/Bidirectional-Attention-Flow-for-Machine-Seo-Kembhavi/7586b7cca1deba124af80609327395e613a20e9d>`_\n",
    "    for answering reading comprehension questions (ICLR 2017).\n",
    "\n",
    "    The basic layout is pretty simple: encode words as a combination of word embeddings and a\n",
    "    character-level encoder, pass the word representations through a bi-LSTM/GRU, use a matrix of\n",
    "    attentions to put question information into the passage word representations (this is the only\n",
    "    part that is at all non-standard), pass this through another few layers of bi-LSTMs/GRUs, and\n",
    "    do a softmax over span start and span end.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vocab : ``Vocabulary``\n",
    "    text_field_embedder : ``TextFieldEmbedder``\n",
    "        Used to embed the ``question`` and ``passage`` ``TextFields`` we get as input to the model.\n",
    "    num_highway_layers : ``int``\n",
    "        The number of highway layers to use in between embedding the input and passing it through\n",
    "        the phrase layer.\n",
    "    phrase_layer : ``Seq2SeqEncoder``\n",
    "        The encoder (with its own internal stacking) that we will use in between embedding tokens\n",
    "        and doing the bidirectional attention.\n",
    "    attention_similarity_function : ``SimilarityFunction``\n",
    "        The similarity function that we will use when comparing encoded passage and question\n",
    "        representations.\n",
    "    modeling_layer : ``Seq2SeqEncoder``\n",
    "        The encoder (with its own internal stacking) that we will use in between the bidirectional\n",
    "        attention and predicting span start and end.\n",
    "    span_end_encoder : ``Seq2SeqEncoder``\n",
    "        The encoder that we will use to incorporate span start predictions into the passage state\n",
    "        before predicting span end.\n",
    "    dropout : ``float``, optional (default=0.2)\n",
    "        If greater than 0, we will apply dropout with this probability after all encoders (pytorch\n",
    "        LSTMs do not apply dropout to their last layer).\n",
    "    mask_lstms : ``bool``, optional (default=True)\n",
    "        If ``False``, we will skip passing the mask to the LSTM layers.  This gives a ~2x speedup,\n",
    "        with only a slight performance decrease, if any.  We haven't experimented much with this\n",
    "        yet, but have confirmed that we still get very similar performance with much faster\n",
    "        training times.  We still use the mask for all softmaxes, but avoid the shuffling that's\n",
    "        required when using masking with pytorch LSTMs.\n",
    "    evaluation_json_file : ``str``, optional\n",
    "        If given, we will load this JSON into memory and use it to compute official metrics\n",
    "        against.  We need this separately from the validation dataset, because the official metrics\n",
    "        use all of the annotations, while our dataset reader picks the most frequent one.\n",
    "    initializer : ``InitializerApplicator``, optional (default=``InitializerApplicator()``)\n",
    "        Used to initialize the model parameters.\n",
    "    regularizer : ``RegularizerApplicator``, optional (default=``None``)\n",
    "        If provided, will be used to calculate the regularization penalty during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab: Vocabulary,\n",
    "                 text_field_embedder: TextFieldEmbedder,\n",
    "                 num_highway_layers: int,\n",
    "                 state_controller: Seq2SeqEncoder,\n",
    "                 phrase_layer: Seq2SeqEncoder,\n",
    "                 attention_similarity_function: SimilarityFunction,\n",
    "                 modeling_layer: Seq2SeqEncoder,\n",
    "                 dropout: float = 0.2,\n",
    "                 mask_lstms: bool = True,\n",
    "                 initializer: InitializerApplicator = InitializerApplicator(),\n",
    "                 regularizer: Optional[RegularizerApplicator] = None,\n",
    "                 max_timesteps: int = 5) -> None:\n",
    "        #super(Reasonet, self).__init__(vocab, regularizer)\n",
    "        super(Reasonet, self).__init__(vocab)\n",
    "\n",
    "        self._text_field_embedder = text_field_embedder\n",
    "        self._highway_layer = TimeDistributed(Highway(text_field_embedder.get_output_dim(),\n",
    "                                                      num_highway_layers))\n",
    "\n",
    "        self._state_controller = state_controller\n",
    "        self._phrase_layer = phrase_layer\n",
    "        self._matrix_attention = MatrixAttention(attention_similarity_function)\n",
    "        self._modeling_layer = modeling_layer\n",
    "\n",
    "        encoding_dim = phrase_layer.get_output_dim()\n",
    "        modeling_dim = modeling_layer.get_output_dim()\n",
    "        state_controller_dim = modeling_dim\n",
    "\n",
    "        similarity_function = CUDA_wrapper(BilinearSimilarity(state_controller_dim, modeling_dim))\n",
    "        state_rnn = CUDA_wrapper(torch.nn.GRUCell(state_controller_dim, state_controller_dim))\n",
    "\n",
    "        self.termination_gate = CUDA_wrapper(TerminationGate(state_controller_dim))\n",
    "\n",
    "        coef_provider = AttentionCoefProvider(similarity_function, True)\n",
    "\n",
    "        self.reasoner_step = ReasoningProcessStep(\n",
    "            AttentionOverMemory(coef_provider),\n",
    "            StateController(state_rnn)\n",
    "        )\n",
    "        self.max_timesteps = max_timesteps\n",
    "        \n",
    "        span_start_input_dim = 2*modeling_dim\n",
    "        self._span_start_predictor = TimeDistributed(torch.nn.Linear(span_start_input_dim, 1))\n",
    "\n",
    "        span_end_input_dim = 2*modeling_dim\n",
    "        self._span_end_predictor = TimeDistributed(torch.nn.Linear(span_end_input_dim, 1))\n",
    "\n",
    "        self._span_start_accuracy = CategoricalAccuracy()\n",
    "        self._span_end_accuracy = CategoricalAccuracy()\n",
    "        self._span_accuracy = BooleanAccuracy()\n",
    "        self._squad_metrics = SquadEmAndF1()\n",
    "        if dropout > 0:\n",
    "            self._dropout = torch.nn.Dropout(p=dropout)\n",
    "        else:\n",
    "            self._dropout = lambda x: x\n",
    "        self._mask_lstms = mask_lstms\n",
    "\n",
    "        initializer(self)\n",
    "\n",
    "    def forward(self,  # type: ignore\n",
    "                question: Dict[str, torch.LongTensor],\n",
    "                passage: Dict[str, torch.LongTensor],\n",
    "                span_start: torch.IntTensor = None,\n",
    "                span_end: torch.IntTensor = None,\n",
    "                metadata: List[Dict[str, Any]] = None) -> Dict[str, torch.Tensor]:\n",
    "        # pylint: disable=arguments-differ\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        question : Dict[str, torch.LongTensor]\n",
    "            From a ``TextField``.\n",
    "        passage : Dict[str, torch.LongTensor]\n",
    "            From a ``TextField``.  The model assumes that this passage contains the answer to the\n",
    "            question, and predicts the beginning and ending positions of the answer within the\n",
    "            passage.\n",
    "        span_start : ``torch.IntTensor``, optional\n",
    "            From an ``IndexField``.  This is one of the things we are trying to predict - the\n",
    "            beginning position of the answer with the passage.  This is an `inclusive` index.  If\n",
    "            this is given, we will compute a loss that gets included in the output dictionary.\n",
    "        span_end : ``torch.IntTensor``, optional\n",
    "            From an ``IndexField``.  This is one of the things we are trying to predict - the\n",
    "            ending position of the answer with the passage.  This is an `inclusive` index.  If\n",
    "            this is given, we will compute a loss that gets included in the output dictionary.\n",
    "        metadata : ``List[Dict[str, Any]]``, optional\n",
    "            If present, this should contain the question ID, original passage text, and token\n",
    "            offsets into the passage for each instance in the batch.  We use this for computing\n",
    "            official metrics using the official SQuAD evaluation script.  The length of this list\n",
    "            should be the batch size, and each dictionary should have the keys ``id``,\n",
    "            ``original_passage``, and ``token_offsets``.  If you only want the best span string and\n",
    "            don't care about official metrics, you can omit the ``id`` key.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        An output dictionary consisting of:\n",
    "        span_start_logits : torch.FloatTensor\n",
    "            A tensor of shape ``(batch_size, passage_length)`` representing unnormalised log\n",
    "            probabilities of the span start position.\n",
    "        span_start_probs : torch.FloatTensor\n",
    "            The result of ``softmax(span_start_logits)``.\n",
    "        span_end_logits : torch.FloatTensor\n",
    "            A tensor of shape ``(batch_size, passage_length)`` representing unnormalised log\n",
    "            probabilities of the span end position (inclusive).\n",
    "        span_end_probs : torch.FloatTensor\n",
    "            The result of ``softmax(span_end_logits)``.\n",
    "        best_span : torch.IntTensor\n",
    "            The result of a constrained inference over ``span_start_logits`` and\n",
    "            ``span_end_logits`` to find the most probable span.  Shape is ``(batch_size, 2)``.\n",
    "        loss : torch.FloatTensor, optional\n",
    "            A scalar loss to be optimised.\n",
    "        best_span_str : List[str]\n",
    "            If sufficient metadata was provided for the instances in the batch, we also return the\n",
    "            string from the original passage that the model thinks is the best answer to the\n",
    "            question.\n",
    "        \"\"\"\n",
    "        embedded_question = self._highway_layer(self._text_field_embedder(question))\n",
    "        embedded_passage = self._highway_layer(self._text_field_embedder(passage))\n",
    "        batch_size = embedded_question.size(0)\n",
    "        passage_length = embedded_passage.size(1)\n",
    "        question_mask = util.get_text_field_mask(question).float()\n",
    "        passage_mask = util.get_text_field_mask(passage).float()\n",
    "        question_lstm_mask = question_mask if self._mask_lstms else None\n",
    "        passage_lstm_mask = passage_mask if self._mask_lstms else None\n",
    "\n",
    "        # We use question_last_state to initialize state controller\n",
    "        question_encoding, question_last_state = self._phrase_layer(embedded_question, question_lstm_mask)\n",
    "        passage_encoding, _ =  self._phrase_layer(embedded_passage, passage_lstm_mask)\n",
    "\n",
    "        encoded_question = self._dropout(question_encoding)\n",
    "        encoded_passage = self._dropout(passage_encoding)\n",
    "        encoding_dim = encoded_question.size(-1)\n",
    "\n",
    "        # Shape: (batch_size, passage_length, question_length)\n",
    "        passage_question_similarity = self._matrix_attention(encoded_passage, encoded_question)\n",
    "        # Shape: (batch_size, passage_length, question_length)\n",
    "        passage_question_attention = util.last_dim_softmax(passage_question_similarity, question_mask)\n",
    "        # Shape: (batch_size, passage_length, encoding_dim)\n",
    "        passage_question_vectors = util.weighted_sum(encoded_question, passage_question_attention)\n",
    "\n",
    "        # We replace masked values with something really negative here, so they don't affect the\n",
    "        # max below.\n",
    "        masked_similarity = util.replace_masked_values(passage_question_similarity,\n",
    "                                                       question_mask.unsqueeze(1),\n",
    "                                                       -1e7)\n",
    "        # Shape: (batch_size, passage_length)\n",
    "        question_passage_similarity = masked_similarity.max(dim=-1)[0].squeeze(-1)\n",
    "        # Shape: (batch_size, passage_length)\n",
    "        question_passage_attention = util.masked_softmax(question_passage_similarity, passage_mask)\n",
    "        # Shape: (batch_size, encoding_dim)\n",
    "        question_passage_vector = util.weighted_sum(encoded_passage, question_passage_attention)\n",
    "        # Shape: (batch_size, passage_length, encoding_dim)\n",
    "        tiled_question_passage_vector = question_passage_vector.unsqueeze(1).expand(batch_size,\n",
    "                                                                                    passage_length,\n",
    "                                                                                    encoding_dim)\n",
    "\n",
    "        # Shape: (batch_size, passage_length, encoding_dim * 4)\n",
    "        final_merged_passage = torch.cat([encoded_passage,\n",
    "                                          passage_question_vectors,\n",
    "                                          encoded_passage * passage_question_vectors,\n",
    "                                          encoded_passage * tiled_question_passage_vector],\n",
    "                                         dim=-1)\n",
    "\n",
    "        modeled_passage = self._dropout(self._modeling_layer(final_merged_passage, passage_lstm_mask))\n",
    "        modeling_dim = modeled_passage.size(-1)\n",
    "\n",
    "        # !!! modelled passage = M\n",
    "        M = modeled_passage\n",
    "        \n",
    "        no_answer_yet = CUDA_wrapper(torch.ones(batch_size).byte())\n",
    "        \n",
    "        span_start_logits_final = CUDA_wrapper(torch.zeros(batch_size, passage_length))\n",
    "        span_end_logits_final = CUDA_wrapper(torch.zeros(batch_size, passage_length))\n",
    "        \n",
    "        expected_reward = 0\n",
    "        reasoner_last_state = question_last_state\n",
    "        proceed_until_now_prob = 1.\n",
    "        for step in range(self.max_timesteps):\n",
    "            reasoner_last_state = self.reasoner_step.forward(reasoner_last_state, M)\n",
    "            proceed_prob, stop_prob = self.termination_gate.forward(reasoner_last_state)\n",
    "            \n",
    "            # Shape: (batch_size, passage_length, modeling_dim)\n",
    "            tiled_reasoner_last_state = reasoner_last_state.unsqueeze(1).expand(\n",
    "                batch_size, passage_length, modeling_dim\n",
    "            )\n",
    "\n",
    "            # Shape: (batch_size, passage_length, encoding_dim * 4 + modeling_dim))\n",
    "            answer_ready_representation = self._dropout(\n",
    "                torch.cat([modeled_passage, modeled_passage * tiled_reasoner_last_state], dim=-1)\n",
    "            )\n",
    "\n",
    "            # ! Start prediction\n",
    "\n",
    "            # Shape: (batch_size, passage_length)\n",
    "            span_start_logits = self._span_start_predictor(answer_ready_representation).squeeze(-1)\n",
    "\n",
    "            # Shape: (batch_size, passage_length)\n",
    "            span_end_logits = self._span_end_predictor(answer_ready_representation).squeeze(-1)\n",
    "\n",
    "            # ! End prediction\n",
    "\n",
    "            may_be_answer_now = torch.bernoulli(stop_prob.data.squeeze()).byte()\n",
    "            if step < self.max_timesteps - 1:\n",
    "                answer_now = may_be_answer_now * no_answer_yet\n",
    "            else:\n",
    "                answer_now = no_answer_yet\n",
    "            no_answer_yet = no_answer_yet * (1 - answer_now)\n",
    "            \n",
    "            span_start_logits_final += answer_now.unsqueeze(-1).float() * span_start_logits.data\n",
    "            span_end_logits_final += answer_now.unsqueeze(-1).float() * span_end_logits.data\n",
    "\n",
    "            span_start_logits = util.replace_masked_values(span_start_logits, passage_mask, -1e7)\n",
    "            span_end_logits = util.replace_masked_values(span_end_logits, passage_mask, -1e7)\n",
    "            \n",
    "            if span_start is not None:\n",
    "                #loss = nll_loss(util.masked_log_softmax(span_start_logits, passage_mask), span_start.squeeze(-1))\n",
    "                #loss += nll_loss(util.masked_log_softmax(span_end_logits, passage_mask), span_end.squeeze(-1))\n",
    "                reward = batchwise_index(\n",
    "                    util.masked_log_softmax(span_start_logits, passage_mask), span_start.squeeze(-1)\n",
    "                ) + batchwise_index(\n",
    "                    util.masked_log_softmax(span_end_logits, passage_mask), span_end.squeeze(-1)\n",
    "                )\n",
    "                #early_answer_penalty = int(step < 1)\n",
    "                early_answer_penalty = 0\n",
    "                #late_answer_penalty = 1\n",
    "                late_answer_penalty = 0\n",
    "                if step < self.max_timesteps - 1:\n",
    "                    expected_reward += torch.mean(\n",
    "                        reward * stop_prob * proceed_until_now_prob * (1 + early_answer_penalty)\n",
    "                    )\n",
    "                else:\n",
    "                    expected_reward += torch.mean(reward * proceed_until_now_prob * (1 + late_answer_penalty))\n",
    "            proceed_until_now_prob = proceed_until_now_prob * proceed_prob\n",
    "\n",
    "        span_start_logits = Variable(span_start_logits_final, requires_grad=False)\n",
    "        span_end_logits = Variable(span_end_logits_final, requires_grad=False)\n",
    "        \n",
    "        span_start_logits = util.replace_masked_values(span_start_logits, passage_mask, -1e7)\n",
    "        span_end_logits = util.replace_masked_values(span_end_logits, passage_mask, -1e7)\n",
    "            \n",
    "        # Shape: (batch_size, passage_length)\n",
    "        span_start_probs = util.masked_softmax(span_start_logits, passage_mask)\n",
    "        # Shape: (batch_size, passage_length)\n",
    "        span_end_probs = util.masked_softmax(span_end_logits, passage_mask)\n",
    "\n",
    "        best_span = self._get_best_span(span_start_logits, span_end_logits)\n",
    "\n",
    "        output_dict = {\n",
    "            \"span_start_logits\": span_start_logits,\n",
    "            \"span_start_probs\": span_start_probs,\n",
    "            \"span_end_logits\": span_end_logits,\n",
    "            \"span_end_probs\": span_end_probs,\n",
    "            \"best_span\": best_span\n",
    "        }\n",
    "        if span_start is not None:\n",
    "            self._span_start_accuracy(span_start_logits, span_start.squeeze(-1))\n",
    "            self._span_end_accuracy(span_end_logits, span_end.squeeze(-1))\n",
    "            self._span_accuracy(best_span, torch.stack([span_start, span_end], -1))\n",
    "            output_dict[\"loss\"] = -expected_reward\n",
    "            \n",
    "        if metadata is not None:\n",
    "            output_dict['best_span_str'] = []\n",
    "            for i in range(batch_size):\n",
    "                passage_str = metadata[i]['original_passage']\n",
    "                offsets = metadata[i]['token_offsets']\n",
    "                predicted_span = tuple(best_span[i].data.cpu().numpy())\n",
    "                start_offset = offsets[predicted_span[0]][0]\n",
    "                end_offset = offsets[predicted_span[1]][1]\n",
    "                best_span_string = passage_str[start_offset:end_offset]\n",
    "                output_dict['best_span_str'].append(best_span_string)\n",
    "                answer_texts = metadata[i].get('answer_texts', [])\n",
    "                if answer_texts:\n",
    "                    self._squad_metrics(best_span_string, answer_texts)\n",
    "        \n",
    "        return output_dict\n",
    "\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        exact_match, f1_score = self._squad_metrics.get_metric(reset)\n",
    "        metrics = {\n",
    "            'start_acc': self._span_start_accuracy.get_metric(reset),\n",
    "            'end_acc': self._span_end_accuracy.get_metric(reset),\n",
    "            'span_acc': self._span_accuracy.get_metric(reset),\n",
    "            'em': exact_match,\n",
    "            'f1': f1_score,\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_best_span(span_start_logits: Variable, span_end_logits: Variable) -> Variable:\n",
    "        if span_start_logits.dim() != 2 or span_end_logits.dim() != 2:\n",
    "            raise ValueError(\"Input shapes must be (batch_size, passage_length)\")\n",
    "        batch_size, passage_length = span_start_logits.size()\n",
    "        max_span_log_prob = [-1e20] * batch_size\n",
    "        span_start_argmax = [0] * batch_size\n",
    "        best_word_span = Variable(span_start_logits.data.new()\n",
    "                                  .resize_(batch_size, 2).fill_(0)).long()\n",
    "\n",
    "        span_start_logits = span_start_logits.data.cpu().numpy()\n",
    "        span_end_logits = span_end_logits.data.cpu().numpy()\n",
    "\n",
    "        for b in range(batch_size):  # pylint: disable=invalid-name\n",
    "            for j in range(passage_length):\n",
    "                val1 = span_start_logits[b, span_start_argmax[b]]\n",
    "                if val1 < span_start_logits[b, j]:\n",
    "                    span_start_argmax[b] = j\n",
    "                    val1 = span_start_logits[b, j]\n",
    "\n",
    "                val2 = span_end_logits[b, j]\n",
    "\n",
    "                if val1 + val2 > max_span_log_prob[b]:\n",
    "                    best_word_span[b, 0] = span_start_argmax[b]\n",
    "                    best_word_span[b, 1] = j\n",
    "                    max_span_log_prob[b] = val1 + val2\n",
    "        return best_word_span\n",
    "\n",
    "    @classmethod\n",
    "    def from_params(cls, vocab: Vocabulary, params: Params) -> 'BidirectionalAttentionFlow':\n",
    "        embedder_params = params.pop(\"text_field_embedder\")\n",
    "        text_field_embedder = TextFieldEmbedder.from_params(vocab, embedder_params)\n",
    "        num_highway_layers = params.pop(\"num_highway_layers\")\n",
    "        state_controller = Seq2SeqEncoder.from_params(params.pop(\"state_controller\"))\n",
    "        phrase_layer = Seq2SeqEncoder.from_params(params.pop(\"phrase_layer\"))\n",
    "        similarity_function = SimilarityFunction.from_params(params.pop(\"similarity_function\"))\n",
    "        modeling_layer = Seq2SeqEncoder.from_params(params.pop(\"modeling_layer\"))\n",
    "        dropout = params.pop('dropout', 0.2)\n",
    "\n",
    "        # TODO: Remove the following when fully deprecated\n",
    "        evaluation_json_file = params.pop('evaluation_json_file', None)\n",
    "        if evaluation_json_file is not None:\n",
    "            logger.warning(\"the 'evaluation_json_file' model parameter is deprecated, please remove\")\n",
    "\n",
    "        init_params = params.pop('initializer', None)\n",
    "        reg_params = params.pop('regularizer', None)\n",
    "        initializer = (InitializerApplicator.from_params(init_params)\n",
    "                       if init_params is not None\n",
    "                       else InitializerApplicator())\n",
    "        regularizer = RegularizerApplicator.from_params(reg_params) if reg_params is not None else None\n",
    "\n",
    "        mask_lstms = params.pop('mask_lstms', True)\n",
    "        params.assert_empty(cls.__name__)\n",
    "        return cls(vocab=vocab,\n",
    "                   text_field_embedder=text_field_embedder,\n",
    "                   num_highway_layers=num_highway_layers,\n",
    "                   state_controller=state_controller,\n",
    "                   phrase_layer=phrase_layer,\n",
    "                   attention_similarity_function=similarity_function,\n",
    "                   modeling_layer=modeling_layer,\n",
    "                   dropout=dropout,\n",
    "                   mask_lstms=mask_lstms,\n",
    "                   initializer=initializer,\n",
    "                   regularizer=regularizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "import percache\n",
    "\n",
    "from allennlp.common.checks import ensure_pythonhashseed_set\n",
    "from allennlp.common.params import Params\n",
    "from allennlp.common.tee_logger import TeeLogger\n",
    "#from allennlp.common.util import prepare_environment\n",
    "from allennlp.data import Dataset, Vocabulary\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.iterators.data_iterator import DataIterator\n",
    "from allennlp.models.archival import archive_model\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "from typing import Any, Callable, Dict, List, TypeVar, Union\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "from allennlp.common.checks import log_pytorch_version_info\n",
    "from allennlp.common.params import Params\n",
    "\n",
    "JsonDict = Dict[str, Any] # pylint: disable=invalid-name\n",
    "\n",
    "def prepare_environment(params: Union[Params, Dict[str, Any]]):\n",
    "    \"\"\"\n",
    "    Sets random seeds for reproducible experiments. This may not work as expected\n",
    "    if you use this from within a python project in which you have already imported Pytorch.\n",
    "    If you use the scripts/run_model.py entry point to training models with this library,\n",
    "    your experiments should be reasonably reproducible. If you are using this from your own\n",
    "    project, you will want to call this function before importing Pytorch. Complete determinism\n",
    "    is very difficult to achieve with libraries doing optimized linear algebra due to massively\n",
    "    parallel execution, which is exacerbated by using GPUs.\n",
    "    Parameters\n",
    "    ----------\n",
    "    params: Params object or dict, required.\n",
    "        A ``Params`` object or dict holding the json parameters.\n",
    "    \"\"\"\n",
    "    seed = params.pop(\"random_seed\", 13370)\n",
    "    numpy_seed = params.pop(\"numpy_seed\", 1337)\n",
    "    torch_seed = params.pop(\"pytorch_seed\", 133)\n",
    "\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    if numpy_seed is not None:\n",
    "        numpy.random.seed(numpy_seed)\n",
    "    if torch_seed is not None:\n",
    "        torch.manual_seed(torch_seed)\n",
    "        # Seed all GPUs with the same seed if available.\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(torch_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from allennlp.commands.train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serialization_dir = './serialization_dir_'\n",
    "cache_dir = './cache_dir_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PARAM:allennlp.common.params:random_seed = 13370\n",
      "PARAM:allennlp.common.params:numpy_seed = 1337\n",
      "PARAM:allennlp.common.params:pytorch_seed = 133\n",
      "PARAM:allennlp.common.params:dataset_reader.type = squad\n",
      "PARAM:allennlp.common.params:dataset_reader.tokenizer.type = word\n",
      "PARAM:allennlp.common.params:dataset_reader.tokenizer.word_splitter.type = spacy\n",
      "PARAM:allennlp.common.params:dataset_reader.tokenizer.word_filter.type = pass_through\n",
      "PARAM:allennlp.common.params:dataset_reader.tokenizer.word_stemmer.type = pass_through\n",
      "PARAM:allennlp.common.params:dataset_reader.tokenizer.start_tokens = None\n",
      "PARAM:allennlp.common.params:dataset_reader.tokenizer.end_tokens = None\n",
      "PARAM:allennlp.common.params:dataset_reader.token_indexers.tokens.type = single_id\n",
      "PARAM:allennlp.common.params:dataset_reader.token_indexers.tokens.namespace = tokens\n",
      "PARAM:allennlp.common.params:dataset_reader.token_indexers.tokens.lowercase_tokens = True\n",
      "PARAM:allennlp.common.params:dataset_reader.token_indexers.token_characters.type = characters\n",
      "PARAM:allennlp.common.params:dataset_reader.token_indexers.token_characters.namespace = token_characters\n",
      "PARAM:allennlp.common.params:dataset_reader.token_indexers.token_characters.character_tokenizer.byte_encoding = utf-8\n",
      "PARAM:allennlp.common.params:dataset_reader.token_indexers.token_characters.character_tokenizer.lowercase_characters = False\n",
      "PARAM:allennlp.common.params:dataset_reader.token_indexers.token_characters.character_tokenizer.start_tokens = [259]\n",
      "PARAM:allennlp.common.params:dataset_reader.token_indexers.token_characters.character_tokenizer.end_tokens = [260]\n",
      "PARAM:allennlp.common.params:train_data_path = ./squad/train-v1.1.json\n",
      "INFO:__main__:Reading training data from ./squad/train-v1.1.json\n",
      "INFO:allennlp.data.dataset_readers.squad:Reading file at ./squad/train-v1.1.json\n",
      "INFO:allennlp.data.dataset_readers.squad:Reading the dataset\n",
      "100%|##########| 442/442 [00:34<00:00, 12.71it/s]\n",
      "PARAM:allennlp.common.params:validation_data_path = ./squad/dev-v1.1.json\n",
      "INFO:__main__:Reading validation data from ./squad/dev-v1.1.json\n",
      "INFO:allennlp.data.dataset_readers.squad:Reading file at ./squad/dev-v1.1.json\n",
      "INFO:allennlp.data.dataset_readers.squad:Reading the dataset\n",
      "100%|##########| 48/48 [00:04<00:00, 11.47it/s]\n",
      "PARAM:allennlp.common.params:vocabulary.directory_path = None\n",
      "PARAM:allennlp.common.params:vocabulary.min_count = 1\n",
      "PARAM:allennlp.common.params:vocabulary.max_vocab_size = None\n",
      "PARAM:allennlp.common.params:vocabulary.non_padded_namespaces = ('*tags', '*labels')\n",
      "INFO:allennlp.data.vocabulary:Fitting token dictionary from dataset.\n",
      "100%|##########| 98169/98169 [00:46<00:00, 2120.96it/s]\n",
      "PARAM:allennlp.common.params:iterator.type = bucket\n",
      "PARAM:allennlp.common.params:iterator.sorting_keys = [['passage', 'num_tokens'], ['question', 'num_tokens']]\n",
      "PARAM:allennlp.common.params:iterator.padding_noise = 0.1\n",
      "PARAM:allennlp.common.params:iterator.biggest_batch_first = False\n",
      "PARAM:allennlp.common.params:iterator.batch_size = 40\n",
      "PARAM:allennlp.common.params:model.type = reasonet_dev\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.type = basic\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.type = embedding\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.num_embeddings = None\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.vocab_namespace = tokens\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.embedding_dim = 100\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.pretrained_file = ./glove/glove.6B.100d.txt.gz\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.projection_dim = None\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.trainable = False\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.padding_index = None\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.max_norm = None\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.norm_type = 2.0\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.scale_grad_by_freq = False\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.tokens.sparse = False\n",
      "INFO:allennlp.modules.token_embedders.embedding:Reading embeddings from file\n",
      "INFO:allennlp.modules.token_embedders.embedding:Initializing pre-trained embedding layer\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.type = character_encoding\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.num_embeddings = 262\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.vocab_namespace = token_characters\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.embedding_dim = 16\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.pretrained_file = None\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.projection_dim = None\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.trainable = True\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.padding_index = None\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.max_norm = None\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.norm_type = 2.0\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.scale_grad_by_freq = False\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.embedding.sparse = False\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.encoder.type = cnn\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.encoder.embedding_dim = 16\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.encoder.output_dim = None\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.encoder.num_filters = 100\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.encoder.conv_layer_activation = relu\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.encoder.ngram_filter_sizes = [5]\n",
      "PARAM:allennlp.common.params:model.text_field_embedder.token_characters.dropout = 0.2\n",
      "PARAM:allennlp.common.params:model.num_highway_layers = 2\n",
      "PARAM:allennlp.common.params:model.state_controller.type = lstm\n",
      "PARAM:allennlp.common.params:model.state_controller.batch_first = True\n",
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "PARAM:allennlp.common.params:model.state_controller.bidirectional = True\n",
      "PARAM:allennlp.common.params:model.state_controller.input_size = 200\n",
      "PARAM:allennlp.common.params:model.state_controller.hidden_size = 100\n",
      "PARAM:allennlp.common.params:model.state_controller.num_layers = 1\n",
      "PARAM:allennlp.common.params:model.state_controller.dropout = 0.2\n",
      "PARAM:allennlp.common.params:model.state_controller.batch_first = True\n",
      "PARAM:allennlp.common.params:model.phrase_layer.type = l_lstm\n",
      "PARAM:allennlp.common.params:model.phrase_layer.batch_first = True\n",
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "PARAM:allennlp.common.params:model.phrase_layer.bidirectional = True\n",
      "PARAM:allennlp.common.params:model.phrase_layer.input_size = 200\n",
      "PARAM:allennlp.common.params:model.phrase_layer.hidden_size = 100\n",
      "PARAM:allennlp.common.params:model.phrase_layer.num_layers = 1\n",
      "PARAM:allennlp.common.params:model.phrase_layer.dropout = 0.2\n",
      "PARAM:allennlp.common.params:model.phrase_layer.batch_first = True\n",
      "PARAM:allennlp.common.params:model.similarity_function.type = linear\n",
      "PARAM:allennlp.common.params:model.similarity_function.tensor_1_dim = 200\n",
      "PARAM:allennlp.common.params:model.similarity_function.tensor_2_dim = 200\n",
      "PARAM:allennlp.common.params:model.similarity_function.combination = x,y,x*y\n",
      "PARAM:allennlp.common.params:model.similarity_function.activation = linear\n",
      "PARAM:allennlp.common.params:model.modeling_layer.type = lstm\n",
      "PARAM:allennlp.common.params:model.modeling_layer.batch_first = True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "PARAM:allennlp.common.params:model.modeling_layer.bidirectional = True\n",
      "PARAM:allennlp.common.params:model.modeling_layer.input_size = 800\n",
      "PARAM:allennlp.common.params:model.modeling_layer.hidden_size = 100\n",
      "PARAM:allennlp.common.params:model.modeling_layer.num_layers = 2\n",
      "PARAM:allennlp.common.params:model.modeling_layer.dropout = 0.2\n",
      "PARAM:allennlp.common.params:model.modeling_layer.batch_first = True\n",
      "PARAM:allennlp.common.params:model.dropout = 0.2\n",
      "PARAM:allennlp.common.params:model.evaluation_json_file = None\n",
      "PARAM:allennlp.common.params:model.initializer = None\n",
      "PARAM:allennlp.common.params:model.regularizer = None\n",
      "PARAM:allennlp.common.params:model.mask_lstms = True\n",
      "INFO:allennlp.nn.initializers:Initializing parameters\n",
      "INFO:allennlp.nn.initializers:Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "INFO:allennlp.nn.initializers:   _highway_layer._module._layers.0.bias\n",
      "INFO:allennlp.nn.initializers:   _highway_layer._module._layers.0.weight\n",
      "INFO:allennlp.nn.initializers:   _highway_layer._module._layers.1.bias\n",
      "INFO:allennlp.nn.initializers:   _highway_layer._module._layers.1.weight\n",
      "INFO:allennlp.nn.initializers:   _matrix_attention._similarity_function._bias\n",
      "INFO:allennlp.nn.initializers:   _matrix_attention._similarity_function._weight_vector\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_hh_l1\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_hh_l1_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_ih_l1\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.bias_ih_l1_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_hh_l1\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_hh_l1_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_ih_l1\n",
      "INFO:allennlp.nn.initializers:   _modeling_layer._module.weight_ih_l1_reverse\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.bias_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.bias_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.bias_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.bias_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.weight_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.weight_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.weight_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _phrase_layer._module.weight_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _span_end_predictor._module.bias\n",
      "INFO:allennlp.nn.initializers:   _span_end_predictor._module.weight\n",
      "INFO:allennlp.nn.initializers:   _span_start_predictor._module.bias\n",
      "INFO:allennlp.nn.initializers:   _span_start_predictor._module.weight\n",
      "INFO:allennlp.nn.initializers:   _state_controller._module.bias_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _state_controller._module.bias_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _state_controller._module.bias_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _state_controller._module.bias_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _state_controller._module.weight_hh_l0\n",
      "INFO:allennlp.nn.initializers:   _state_controller._module.weight_hh_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _state_controller._module.weight_ih_l0\n",
      "INFO:allennlp.nn.initializers:   _state_controller._module.weight_ih_l0_reverse\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_token_characters._embedding._module.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_token_characters._encoder._module.conv_layer_0.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_tokens.weight\n",
      "INFO:allennlp.nn.initializers:   termination_gate.linear.bias\n",
      "INFO:allennlp.nn.initializers:   termination_gate.linear.weight\n",
      "INFO:allennlp.data.dataset:Indexing dataset\n",
      "100%|##########| 87599/87599 [01:16<00:00, 1148.29it/s]\n",
      "INFO:allennlp.data.dataset:Indexing dataset\n",
      "100%|##########| 10570/10570 [00:10<00:00, 977.14it/s]\n",
      "PARAM:allennlp.common.params:trainer.patience = 10\n",
      "PARAM:allennlp.common.params:trainer.validation_metric = +em\n",
      "PARAM:allennlp.common.params:trainer.num_epochs = 100\n",
      "PARAM:allennlp.common.params:trainer.cuda_device = 0\n",
      "PARAM:allennlp.common.params:trainer.grad_norm = 5.0\n",
      "PARAM:allennlp.common.params:trainer.grad_clipping = None\n",
      "PARAM:allennlp.common.params:trainer.optimizer.type = adam\n",
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "PARAM:allennlp.common.params:trainer.optimizer.betas = [0.9, 0.9]\n",
      "PARAM:allennlp.common.params:trainer.learning_rate_scheduler.type = reduce_on_plateau\n",
      "INFO:allennlp.common.params:Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.\n",
      "INFO:allennlp.common.params:CURRENTLY DEFINED PARAMETERS: \n",
      "PARAM:allennlp.common.params:trainer.learning_rate_scheduler.factor = 0.5\n",
      "PARAM:allennlp.common.params:trainer.learning_rate_scheduler.mode = max\n",
      "PARAM:allennlp.common.params:trainer.learning_rate_scheduler.patience = 2\n",
      "PARAM:allennlp.common.params:trainer.no_tqdm = True\n",
      "INFO:allennlp.training.trainer:Beginning training.\n",
      "INFO:allennlp.training.trainer:Epoch 1/100\n",
      "INFO:allennlp.training.trainer:Training\n",
      "INFO:allennlp.training.trainer:Batch 1/2190: start_acc: 0.00, end_acc: 0.00, span_acc: 0.00, em: 0.00, f1: 0.11, loss: 9.35 ||\n",
      "INFO:allennlp.training.trainer:Batch 20/2190: start_acc: 0.02, end_acc: 0.02, span_acc: 0.00, em: 0.00, f1: 0.06, loss: 9.61 ||\n",
      "INFO:allennlp.training.trainer:Batch 40/2190: start_acc: 0.03, end_acc: 0.03, span_acc: 0.01, em: 0.01, f1: 0.07, loss: 9.35 ||\n",
      "INFO:allennlp.training.trainer:Batch 61/2190: start_acc: 0.04, end_acc: 0.04, span_acc: 0.01, em: 0.01, f1: 0.07, loss: 9.06 ||\n",
      "INFO:allennlp.training.trainer:Batch 81/2190: start_acc: 0.04, end_acc: 0.05, span_acc: 0.01, em: 0.01, f1: 0.07, loss: 8.86 ||\n",
      "INFO:allennlp.training.trainer:Batch 101/2190: start_acc: 0.05, end_acc: 0.05, span_acc: 0.01, em: 0.01, f1: 0.08, loss: 8.74 ||\n",
      "INFO:allennlp.training.trainer:Batch 125/2190: start_acc: 0.05, end_acc: 0.06, span_acc: 0.02, em: 0.02, f1: 0.08, loss: 8.52 ||\n",
      "INFO:allennlp.training.trainer:Batch 144/2190: start_acc: 0.06, end_acc: 0.06, span_acc: 0.02, em: 0.02, f1: 0.08, loss: 8.46 ||\n",
      "INFO:allennlp.training.trainer:Batch 164/2190: start_acc: 0.06, end_acc: 0.06, span_acc: 0.02, em: 0.02, f1: 0.08, loss: 8.39 ||\n",
      "INFO:allennlp.training.trainer:Batch 187/2190: start_acc: 0.06, end_acc: 0.07, span_acc: 0.02, em: 0.02, f1: 0.09, loss: 8.29 ||\n",
      "INFO:allennlp.training.trainer:Batch 208/2190: start_acc: 0.06, end_acc: 0.07, span_acc: 0.02, em: 0.02, f1: 0.09, loss: 8.24 ||\n",
      "INFO:allennlp.training.trainer:Batch 228/2190: start_acc: 0.07, end_acc: 0.07, span_acc: 0.02, em: 0.03, f1: 0.09, loss: 8.19 ||\n",
      "INFO:allennlp.training.trainer:Batch 251/2190: start_acc: 0.07, end_acc: 0.07, span_acc: 0.03, em: 0.03, f1: 0.09, loss: 8.12 ||\n",
      "INFO:allennlp.training.trainer:Batch 272/2190: start_acc: 0.07, end_acc: 0.08, span_acc: 0.03, em: 0.03, f1: 0.10, loss: 8.08 ||\n",
      "INFO:allennlp.training.trainer:Batch 290/2190: start_acc: 0.07, end_acc: 0.08, span_acc: 0.03, em: 0.03, f1: 0.10, loss: 8.05 ||\n"
     ]
    }
   ],
   "source": [
    "prepare_environment(params)\n",
    "\n",
    "os.makedirs(serialization_dir, exist_ok=True)\n",
    "sys.stdout = TeeLogger(os.path.join(serialization_dir, \"stdout.log\"), sys.stdout)  # type: ignore\n",
    "sys.stderr = TeeLogger(os.path.join(serialization_dir, \"stderr.log\"), sys.stderr)  # type: ignore\n",
    "handler = logging.FileHandler(os.path.join(serialization_dir, \"python_logging.log\"))\n",
    "handler.setLevel(logging.INFO)\n",
    "handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(message)s'))\n",
    "logging.getLogger().addHandler(handler)\n",
    "serialization_params = deepcopy(params).as_dict(quiet=True)\n",
    "with open(os.path.join(serialization_dir, \"model_params.json\"), \"w\") as param_file:\n",
    "    json.dump(serialization_params, param_file, indent=4)\n",
    "\n",
    "cache = percache.Cache(cache_dir)\n",
    "\n",
    "# Now we begin assembling the required parts for the Trainer.\n",
    "dataset_reader = DatasetReader.from_params(params.pop('dataset_reader'))\n",
    "train_data_path = params.pop('train_data_path')\n",
    "logger.info(\"Reading training data from %s\", train_data_path)\n",
    "train_data = dataset_reader.read(train_data_path)\n",
    "\n",
    "validation_data_path = params.pop('validation_data_path', None)\n",
    "if validation_data_path is not None:\n",
    "    logger.info(\"Reading validation data from %s\", validation_data_path)\n",
    "    validation_data = dataset_reader.read(validation_data_path)\n",
    "    combined_data = Dataset(train_data.instances + validation_data.instances)\n",
    "else:\n",
    "    validation_data = None\n",
    "    combined_data = train_data\n",
    "\n",
    "vocab = cache(Vocabulary.from_params)(params.pop(\"vocabulary\", {}), combined_data)\n",
    "iterator = cache(DataIterator.from_params)(params.pop(\"iterator\"))\n",
    "\n",
    "cache.close()\n",
    "\n",
    "vocab.save_to_files(os.path.join(serialization_dir, \"vocabulary\"))\n",
    "\n",
    "model = Model.from_params(vocab, params.pop('model'))\n",
    "\n",
    "train_data.index_instances(vocab)\n",
    "if validation_data:\n",
    "    validation_data.index_instances(vocab)\n",
    "\n",
    "trainer_params = params.pop(\"trainer\")\n",
    "trainer = Trainer.from_params(model,\n",
    "                              serialization_dir,\n",
    "                              iterator,\n",
    "                              train_data,\n",
    "                              validation_data,\n",
    "                              trainer_params)\n",
    "params.assert_empty('base train command')\n",
    "trainer.train()\n",
    "\n",
    "# Now tar up results\n",
    "archive_model(serialization_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
